<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[漫画下载(十五)]]></title>
    <url>%2F2020%2F09%2F27%2F%E6%BC%AB%E7%94%BB%E4%B8%8B%E8%BD%BD%EF%BC%88%E5%A4%84%E7%90%86%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD%E5%8F%8A%E7%AE%80%E5%8D%95%E5%8F%8D%E7%88%AC%E8%99%AB%EF%BC%89(%E5%8D%81%E4%BA%94)%2F</url>
    <content type="text"><![CDATA[在动漫之家选择一本漫画下载，下载一本已完结的。《一条狗》url=https://www.dmzj.com/info/yitiaogou.html 想下载这本动漫，需要保存所有章节的图片到本地。先捋捋思路： 拿到所有章节名和章节链接 根据章节链接爬取章节里的所有漫画图片 根据章节名，分类保存漫画 ** 获取章节名和章节链接 分析一下html 分析可以发现div标签下有个ul标签，ul标签是距离a标签最近的标签。 用上一篇文章讲解的Beautiful Soup，实际上直接匹配最近的class属性为list_con_li的ul标签即可。代码如下： 123456789101112131415161718import requestsfrom bs4 import BeautifulSouptarget_url=&apos;https://www.dmzj.com/info/yitiaogou.html&apos;req=requests.get(url=target_url)html=req.textbs=BeautifulSoup(html,&apos;lxml&apos;)list_con_li=bs.find(&apos;ul&apos;,class_=&apos;list_con_li&apos;)comic_list=list_con_li.find_all(&apos;a&apos;)chapter_name=[]chapter_urls=[]for comic in comic_list: href=comic.get(&apos;href&apos;) name=comic.text chapter_name.insert(0,name) chapter_urls.insert(0,href)print(chapter_name)print(chapter_urls) 章节名和章节链接就搞定了。 获取漫画图片地址 我们只要分析在一个章节里怎么获取图片，就能批量的在各个章节获取漫画图片。 我们先看第一章的内容。 url：https://www.dmzj.com/view/yitiaogou/34449.html#@page=1 打开第一章的链接，你会发现，链接后面自动添加了#@page=1但是这个并不是图片的真实地址，而是这个页面的地址，要下载图片，我们首先要拿到真实地址，审查元素找图片，页面无法右键这就是反爬虫手段，不过我们可以通过F12调出审查元素窗口。有的网站甚至还会把F12都禁掉，这也是反爬虫手段。面对这种禁止看页面源码的初级手段，一个优雅的通用解决方法就是，在链接前面加个view-source:。 view-source:https://www.dmzj.com/view/yitiaogou/34449.html 用这个链接，直接看的就是页面源码。 更简单的办法是，将鼠标焦点放在浏览器地址栏，然后按下F12调出调试窗口。在Network中找到我们的图片真实地址，链接如下： 1https://images.dmzj.com/img/chapterpic/175/866/14417836509461.jpg 这就是图片的真实地址，拿着这个链接去html页面中搜索，可以找到是有这个图片链接的。 但是用view-source:https://www.dmzj.com/view/yitiaogou/34449.html打开的页面找不到这个图片链接。说明这个图片是**动态加载**的。 view-source:方法只能看页面源码，不管动态加载的内容，这里面没有图片链接，就说明图片是动态加载的。使用JavaScript动态加载，无外乎两种方式： 外部加载 内部加载 外部加载就是在html页面中，以引用的形式，加载一个js，例如这样： 这段代码的意思是，引用xxxxxx.com域名下的call.js文件。内部加载就是javascript脚本内容写在html内，例如这个漫画网站。一般这种动态加载都是程序合成的。12345&lt;script type=&quot;text/javascript&quot;&gt; var arr_img = new Array(); var page = &apos;&apos;; eval(function(p,a,c,k,e,d)&#123;e=function(c)&#123;return c.toString(36)&#125;;if(!&apos;&apos;.replace(/^/,String))&#123;while(c--)&#123;d[c.toString(a)]=k[c]||c.toString(a)&#125;k=[function(e)&#123;return d[e]&#125;];e=function()&#123;return&apos;\\w+&apos;&#125;;c=1&#125;;while(c--)&#123;if(k[c])&#123;p=p.replace(new RegExp(&apos;\\b&apos;+e(c)+&apos;\\b&apos;,&apos;g&apos;),k[c])&#125;&#125;return p&#125;(&apos;7 8=\&apos;&#123;&quot;9&quot;:&quot;6&quot;,&quot;5&quot;:&quot;0&quot;,&quot;2&quot;:&quot;3\\/4\\/a\\/b\\/h.i&quot;,&quot;g&quot;:&quot;1&quot;,&quot;d&quot;:&quot;e&quot;,&quot;j&quot;:&quot;\\c\\f&quot;&#125;\&apos;;&apos;,20,20,&apos;||page_url|img|chapterpic|hidden|34449|var|pages|id|175|866|u7b2c01|chapter_order|10|u8bdd|sum_pages|14417836509461|jpg|chapter_name&apos;.split(&apos;|&apos;),0,&#123;&#125;))&lt;/script&gt; 图片链接：https://images.dmzj.com/img/chapterpic/175/866/14417836509461.jpg 由图可以看出链接的这几个数字就是合成的，可以把这些数字弄出来，拼接成图片链接。 未完。。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[爬取小说（十四）]]></title>
    <url>%2F2020%2F09%2F25%2F%E7%88%AC%E5%8F%96%E5%B0%8F%E8%AF%B4%EF%BC%88%E5%8D%81%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1.背景介绍：小说网站，“新笔趣阁”：https://www.xsbiquge.com/“新笔趣阁”只支持在线浏览，不支持小说打包下载。本文就是练习下载一篇名为《奇门地师》的网络小说。2.爬虫步骤爬虫其实很简单，可以大致分为三个步骤： 发起请求：我们需要先明确如何发起HTTP请求，获取到数据。 解析请求：获取到的数据乱七八糟，我们需要提取出我们想要的数据。 保存数据：将我们想要的数据，保存下来。 发起请求，就用request就行。解析的工具有很多，比如xpath、Beautiful Soup、正则表达式等。本文就用一个简单的经典小工具，Beautiful Soup来解析数据。保存数据，就是常规的文本保存。 3.Beautiful Soup安装我们可以使用pip来安装，在cmd命令窗口中输入如下命令安装：1pip install beautifulsoup4 安装好后，还需要安装lxml，这是解析HTML需要用到的依赖：1pip install lxml 4.开始我们先看下《奇门地师》小说的第一章内容。https://www.xsbiquge.com/97_97912/441675.html 我们先获取HTML信息试一试，编写代码如下：1234567import requestsif __name__==&apos;__main__&apos;: target=&apos;https://www.xsbiquge.com/97_97912/441675.html&apos; req=requests.get(url=target) req.encoding=&apos;utf-8&apos; print(req.text) 爬虫的第一步“发起请求”，得到的结果如下： 可以看到，我们获取了html信息，里面有我们想要的小说正文内容，但是也包含了一些其他内容，我们不关心div、br这些html标签 如何把正文内容从这些众多的html标签中提取出来? 进入爬虫的第二步“解析数据”也就是使用Beautiful Soup进行解析 现在，对目标页面进入审查元素，会看到： 文章的内容存在了id=content的div标签里，可以使用Beautiful Soup提取我们想要的正文内容，代码如下：12345678910import requestsfrom bs4 import BeautifulSoupif __name__==&apos;__main__&apos;: target=&apos;https://www.xsbiquge.com/97_97912/441675.html&apos; req=requests.get(url=target) req.encoding=&apos;utf-8&apos; html=req.text bs=BeautifulSoup(html,&apos;lxml&apos;) texts=bs.find(&apos;div&apos;,id=&apos;content&apos;) print(texts) bs.find(‘div’,id=’content’)的意思就是，找到id属性为content的div标签。 可以看到，正文内容已经顺利提取，但是里面还有一些div和br这类标签，我们需要进一步清洗数据。 1234567891011import requestsfrom bs4 import BeautifulSoupif __name__==&apos;__main__&apos;: target=&apos;https://www.xsbiquge.com/97_97912/441675.html&apos; req=requests.get(url=target) req.encoding=&apos;utf-8&apos; html=req.text bs=BeautifulSoup(html,&apos;lxml&apos;) texts=bs.find(&apos;div&apos;,id=&apos;content&apos;) print(texts.text.strip().split(&apos;\xa0&apos;*4)) texts.text是提取所有文字，然后在使用strip方法去掉回车，最后使用split方式根据\xa0切分数据，因为每一段的开头，都有四个空格。 扩展： \xa0 是不间断空白符&nbsp; 我们通常所用的空格是\x20，是在标准ASCII可见字符，0x20~0x7e范围内。而\xa0属于latin1(ISO/IEC_8859_1)中的扩展字符集，代表空白符&nbsp;(non-breaking_apsce).latin1字符集向下兼容ASCII（0x20~0x7e）。通常我们见到的字符多数是latin1的。 \u3000 是全角的空白符 根据Unicode编码标准及其基本多语言的定义，\u3000属于CJK标点符号区块内，是空白符之一。它的名字是 Ideographic Space ，有人译作表意字空格、象形字空格等。顾名思义，就是全角的 CJK 空格。它跟 nbsp 不一样，是可以被换行间断的。常用于制造缩进。 程序运行结果如下： 所有的内容，已经清洗干净，保存到一个列表里了。小说正文，已经顺利获取到了。要想下载整本小说，我们就要获取每个章节的连接，我们先分析下小说目录：https://www.xsbiquge.com/97_97912 审查元素后发现，所有章节信息，都存放到了id属性为list的div标签下的a标签内，代码： 123456789101112import requestsfrom bs4 import BeautifulSoupif __name__==&apos;__main__&apos;: target=&apos;https://www.xsbiquge.com/97_97912/&apos; req=requests.get(url=target) req.encoding=&apos;utf-8&apos; html=req.text bs=BeautifulSoup(html,&apos;lxml&apos;) chapters=bs.find(&apos;div&apos;,id=&apos;list&apos;) chapters=chapters.find_all(&apos;a&apos;) for chapter in chapters: print(chapter) bs.find(‘div’,id=’list’)就是找到id属性为list的div标签，chapters.find_all(‘a’)就是在找到的div标签里，在提取出所有a标签，运行结果： 可以看到章节链接和章节名我们已经提取出来，但是还需要进一步解析，代码如下：123456789101112131415import requestsfrom bs4 import BeautifulSoupif __name__==&apos;__main__&apos;: server=&apos;https://www.xsbiquge.com&apos; target=&apos;https://www.xsbiquge.com/97_97912/&apos; req=requests.get(url=target) req.encoding=&apos;utf-8&apos; html=req.text bs=BeautifulSoup(html,&apos;lxml&apos;) chapters=bs.find(&apos;div&apos;,id=&apos;list&apos;) chapters=chapters.find_all(&apos;a&apos;) for chapter in chapters: url=chapter.get(&apos;href&apos;) print(chapter.string) print(server+url) chapters.get(‘href’)方法提取了href属性，并拼接出属性url，使用chapters.string方法提取了章节名。 每个章节的链接，章节名，章节内容都有了，接下来就是整合代码，将内容保存到txt即可。 12345678910111213141516171819202122232425262728293031import requestsfrom bs4 import BeautifulSoupfrom tqdm import tqdmdef get_content(target): req=requests.get(url=target) req.encoding=&apos;utf-8&apos; html=req.text bs=BeautifulSoup(html,&apos;lxml&apos;) texts=bs.find(&apos;div&apos;,id=&apos;content&apos;) content=texts.text.strip().split(&apos;\xa0&apos;*4) return contentif __name__==&apos;__main__&apos;: server=&apos;https://www.xsbiquge.com&apos; book_name=&apos;奇门地师.txt&apos; target=&apos;https://www.xsbiquge.com/97_97912/&apos; req=requests.get(url=target) req.encoding=&apos;utf-8&apos; html=req.text bs=BeautifulSoup(html,&apos;lxml&apos;) chapters=bs.find(&apos;div&apos;,id=&apos;list&apos;) chapters=chapters.find_all(&apos;a&apos;) for chapter in tqdm(chapters): url=server+chapter.get(&apos;href&apos;) chapters_name=chapter.string content=get_content(url) with open(book_name,&apos;a&apos;,encoding=&apos;utf-8&apos;) as f: f.write(chapters_name) f.write(&apos;\n&apos;) f.write(&apos;\n&apos;.join(content)) f.write(&apos;\n&apos;) 这样找到保存的txt文件，就可以看到下载的所有内容了。 下载过程中，如果我们使用了tqdm显示下载进度，让下载更加“优雅”，如果没有安装tqdm，可以使用pip进行安装 pip install tqdm 可以看到，小说内容保存到“奇门地师.txt”中，小说一共620章，下载大约七分钟，这样爬取数据很慢，可以使用分布式爬取。使用分布式可以一秒下完。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PyMysql（十）]]></title>
    <url>%2F2020%2F09%2F16%2FPyMysql(%E5%8D%81)%2F</url>
    <content type="text"><![CDATA[pymysql是纯用Python操作MySQL的模块，其使用方法和MySQLdb几乎相同。此次介绍mysql以及在python中如何用pymysql操作数据库, 以及在mysql中存储过程, 触发器以及事务的实现, 对应到pymysql中应该如何操作。 1.准备 首先通过mysql客户端或命令行创建一个数据库user 1CREATE DATABASE USER 然后，在这个数据库下创建一张简单的表people 接着创建几个字段：id，name，age，其中id为主键 123456CREATE TABLE `people` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(10) NOT NULL, `age` varchar(10) NOT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 2.安装pymysql 用pip安装依赖 1pip install pymysql 连接数据库，获取数据连接对象及游标对象 使用pymysql中的connect()方法，传入数据库的HOST地址，端口号，用户名，密码，待操作数据库的名称，即可以获取数据库的连接对象 然后再通过连接对象，获取执行数据库具体操作的游标对象 1234567import pymysql#数据库连接db=pymysql.connect(host=&apos;localhost&apos;, port=3306,user=&apos;root&apos;,password=&apos;root&apos;,database=&apos;user&apos;)#获取游标cursor=db.cursor() 接着，来实现增删改查操作 1.新增 新增包含新增单条数据和多条数据 对于单条数据的插入，只需要编写一条插入的SQL语句，然后作为参数执行上面游标对象的execute(sql)方法，最后使用数据库连接对象的commit()方法将数据提交到数据中]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用python拼接图片（九）]]></title>
    <url>%2F2020%2F09%2F15%2F%E4%BD%BF%E7%94%A8python%E6%8B%BC%E6%8E%A5%E5%9B%BE%E7%89%87(%E4%B9%9D)%2F</url>
    <content type="text"><![CDATA[用python把多张图片按比例缩小，然后拼成一张图片，首先分析一下需求 这个拼图片就像要做一个照片墙，首先要有一张680*680的墙，算出这个墙的面积，然后算出来有多少张照片，拿总的面积除以照片的数量，就算出来每张照片的面积，裁剪好大小正好的照片，这样子就可以把照片都贴这块墙上了。现在思路已经缕清了，要注意上面几个需要运算的数据： 1、墙的面积 2、照片的数量 3、每个照片的面积 4、每个照片的边长 5、每行能够贴的照片数量 处理图片需要用到PIL模块，直接pip安装即可 1pip install pillow 拼接图片如下：`import math # math模块计算平方根from PIL import Image # 导入PIL模块，处理图片import glob # glob模块，获取目录下的文件 size = 680 # 照片墙的边长img1 = Image.new(‘RGBA’, (size, size), ‘white’) 生成一个680*680像素的图片pics = glob.glob(r’C:\Users\admin\Desktop\img/*.png’) glob模块和os.listdir功能一样，获取某个目录下的文件，只不过是它可以支持模糊匹配，图片都放在这个目录下bianchang = int(math.sqrt(size * size / len(pics))) 先用边长乘以边长算出来总面积，然后除以个数，就算出来每个图片的面积，然后面积开方就算出来了边长line_num = int(size / bianchang) 照片墙的边长除以照片的边长就是每行能放照片的数量x = 0 # 列y = 0 # 行for f in pics: # 循环取到每个图片 img = Image.open(f) # 打开图片 img = img.resize((bianchang, bianchang), Image.ANTIALIAS) # resize方法是重置这个图片的尺寸，也就是他的面积，这里用传了2个边长，就算出来了面积 # Image.ANTIALIAS这个参数的意思是，重置尺寸了之后，高质量的图片 img1.paste(img, (x * bianchang, y * bianchang)) # 这里就开始粘贴图片了，(x,y)是列和行，第一开始是0,0在左上角贴了一张， # 这里乘以边长的意思就是，每张照片占的长度 x += 1 # 这个x其实就代表每行贴了几张了，每贴一张就加一 if x == line_num: # 这里判断了一下，这一行是否贴满了， # 如果贴满了就从第二行开始贴，列还是从第1列开始 x = 0 # 列从最前面开始 y += 1 # 第一行贴满了，那就从第二行开始了，行号+1 img1.save(‘photo.png’) 保存图片，这里不能用jpg格式的，前面在创建图片的时候用的是RGBA模式的，只能用png结尾,RGBA模式是一种色彩模式`]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用python生成词云（八）]]></title>
    <url>%2F2020%2F09%2F11%2F%E4%BD%BF%E7%94%A8python%E7%94%9F%E6%88%90%E8%AF%8D%E4%BA%91(%E5%85%AB)%2F</url>
    <content type="text"><![CDATA[什么是词云呢？ 词云就是一些关键词组成的一个图片。大家在网上经常看到，下面看一些例子： 用python生成词云，首先要有一些词，随便找些词放在txt文件里就好了。 首先我们会用到wordcloud这个模块，他可以实现分词，生成我们想要的词云图片，用下面的命令进行安装：1pip install wordcloud 过程如下： 首先先读取到放在txt里面的词，然后给WordCloud，让他帮忙分词，分词的意思就是把里面的一些关键词提取出来，以及指定图片的大小，背景颜色，字体等等。 12345678910from wordcloud import WordCloud #导入词云模块words = open(&apos;test.txt&apos;,encoding=&apos;utf-8&apos;).read()#打开词语文件，获取到词语wordcloud = WordCloud(width=1000, #图片的宽度 height=860, #高度 margin=2, #边距 background_color=&apos;black&apos;,#指定背景颜色 font_path=&apos;C:\Windows\Fonts\simfang.ttf&apos;#设置字体，不然会出现口字乱码，文字的路径是电脑的字体一般路径，可以换成别的 )wordcloud.generate(words) #分词wordcloud.to_file(&apos;test.jpg&apos;)#保存到图片 注意，这个地方可能会报“OSError: cannot open resource”的一个错误，这是由于找不到字体的原因。我上面的字体位置就是系统中字体位置，所以如果报错了，检查一下是否有该字体，更换一下就好。 简单的几行代码就ok拉，下面是生成的效果图 wordcloud这个模块对中文分词支持不怎么好，因为英文的每个单词都是空格分开的，但是中文每个词语都是连着，另外jieba这个模块对中文分词比较好。 先安装jieba这个模块 1pip install jieba 再找个中文词语，保存到test1里面，用jieba分词，保存到test1.jpg里面，代码如下: 123456789101112import jiebafrom wordcloud import WordCloud #导入词云模块words = open(&apos;test1.txt&apos;,encoding=&apos;utf-8&apos;).read()#打开词语文件，获取到词语new_words = &apos; &apos;.join(jieba.cut(words))#使用jieba.cut分词，然后把分好的词变成一个字符串，每个词用空格隔开wordcloud = WordCloud(width=1000, #图片的宽度 height=860, #高度 margin=2, #边距 background_color=&apos;black&apos;,#指定背景颜色 font_path=&apos;C:\Windows\Fonts\simfang.ttf#设置字体，不然会出现口字乱码，文字的路径是电脑的字体一般路径，可以换成别的 )wordcloud.generate(new_words) #分词wordcloud.to_file(&apos;test1.jpg&apos;)#保存到图片 词云已经生成，还可以做成各种形状的，首先先找到一个形状的图片，然后用到PIL模块，处理图片，用numpy把这个图片的各种属性转成数字，这2个模块需要安装，pip安装即可。123pip install PILpip install numpy 原来的高跟鞋参照物 下面是产生高跟鞋形状的词云: 下面是源代码：12345678910111213141516import jieba,numpyfrom PIL import Image#导入PIL模块处理图片from wordcloud import WordCloud #导入词云模块words = open(&apos;test00.txt&apos;,encoding=&apos;utf-8&apos;).read()#打开词语文件，获取到词语new_words = &apos; &apos;.join(jieba.cut(words))#使用jieba.cut分词，然后把分好的词变成一个字符串，每个词用空格隔开alice_mask = numpy.array(Image.open(&apos;test01.png&apos;))#使用pil模块打开这个图片，然后用numpy获取到这个图片各种乱八七糟的属性wordcloud = WordCloud(width=1000, #图片的宽度 height=860, #高度 margin=2, #边距 mask=alice_mask, background_color=&apos;white&apos;,#指定背景颜色 font_path=&apos;C:\Windows\Fonts\simfang.ttf&apos;#设置字体，不然会出现口字乱码，文字的路径是电脑的字体一般路径，可以换成别的 )wordcloud.generate(new_words) #分词wordcloud.to_file(&apos;test02.jpg&apos;)#保存到图片]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[PyQuery模块（七）]]></title>
    <url>%2F2020%2F09%2F08%2FPyQuery%E6%A8%A1%E5%9D%97%EF%BC%88%E4%B8%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[简介PyQuery是一个类似于jQuery的解析网页工具，使用lxml操作xml和html文档，它的语法和jQuery很像。和xpath，beautiful soup比起来，PyQuery更加灵活，提供增加节点的class信息，移除某个节点，提供文本信息功能。 安装 Pyquery需要依赖lxml模块，不装的话，使用会报错。 12pip install lxmlpip install pyquery 解析html的3种方式 12345678910111213141516171819202122from pyquery import PyQueryhtml = &quot;&quot;&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;Baidu&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt;&lt;p class=&quot;content&quot;&gt;搜索&lt;a href=&quot;http://www.baidu.com&quot; class=&quot;link&quot; id=&quot;link1&quot;&gt;&lt;!--首页--&gt;&lt;/a&gt;,&lt;a href=&quot;http://www.baidu.com/page/3.html&quot; class=&quot;link&quot; id=&quot;link2&quot;&gt;搜索1&lt;/a&gt; and&lt;a href=&quot;http://www.baidu.com/page/47.html&quot; class=&quot;link&quot; id=&quot;link3&quot;&gt;搜索2&lt;/a&gt;;请点击上面的链接.&lt;/p&gt;&lt;p class=&quot;content&quot;&gt;.这是广告植入.&lt;/p&gt;&lt;p class=&quot;title&quot;&gt;百度&lt;/p&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;&quot;&quot;&quot;doc = PyQuery(url=&apos;http://www.baidu.com&apos;) #指定url，url里面的html源码doc2 = PyQuery(html) #指定html字符串doc3 = PyQuery(filename=&apos;index.html&apos;) #指定文件print(doc)print(doc2)print(doc3) css选择器css在BeautifulSoup模块里面也用过，用法差不多。具体如下 1234567print(doc2(&apos;.link&apos;)) #通过classprint(doc2(&apos;#link1&apos;)) #通过idprint(doc2(&apos;.content,#link1&apos;)) #找到所有class为content和id为link1的print(doc2(&apos;.content #link1&apos;)) #在content下面找到id为link1的元素print(doc2(&apos;a&apos;))#找到所有的a标签print(doc2(&apos;[href]&apos;))#找到所有带有href属性的元素print(doc2(&apos;a[target=_blank]&apos;))#找到a标签下面target为_blank的 常用方法 1234# eq方法，获取第几个元素a_tags = doc2(&apos;a&apos;)print(a_tags.eq(0)) # a标签里面第一个print(a_tags.eq(1)) # a标签里面第二个 12345678# items()# 如果找到多个元素的话，想循环取元素的话，就得用.items()方法，items就是为了循环用的a_tag = doc2(&apos;a&apos;)for a in a_tag.items(): print(a.text())# text() 、html()# text()方法是获取元素里面的文字的，html()是获取元素的html 123a = doc2(&apos;.content&apos;)print(a.html()) # html格式的print(a.text()) # 只有里面的文字 12345# find方法，查找元素print(doc2.find(&apos;p&apos;).find(&apos;a&apos;)) # 从所有的p标签里面找到a标签print(doc2.find(&apos;p&apos;)) # 找到所有的p标签print(doc2.find(&apos;.content&apos;)) # 找到所有class为content的 12# filter方法，用来筛选print(doc2.find(&apos;a&apos;).filter(&apos;#link1&apos;)) # 先找到a标签，然后从a标签里面筛选出来id为link1的 12# attr方法，获取属性print(doc2(&apos;#link1&apos;).attr((&apos;href&apos;))) # 获取id为link1的href的属性值]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[BeautifulSoup库（六）]]></title>
    <url>%2F2020%2F09%2F03%2FBeautifulSoup%E5%BA%93%EF%BC%88%E5%85%AD%EF%BC%89%20%2F</url>
    <content type="text"><![CDATA[Beautiful Soup简介简单来说，Beautiful Soup是python的一个库，最主要的功能是从网页抓取数据。 Beautiful Soup安装Beautiful Soup 3目前已经停止开发，推荐在现在的项目中使用Beautiful Soup 4，不过它已经被移植到BS4了，也就是说导入时我们需要import bs4。 可以利用pip命令 来安装，如下：1pip install beautifulsoup4 快速使用通过下面的一个例子，对bs4有个简单的了解，以及看一下它的强大之处：12345678910111213141516171819202122232425from bs4 import BeautifulSouphtml = &apos;&apos;&apos;&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;&apos;&apos;&apos;soup = BeautifulSoup(html,&apos;lxml&apos;)print(soup.prettify())print(soup.title)print(soup.title.name)print(soup.title.string)print(soup.title.parent.name)print(soup.p)print(soup.p[&quot;class&quot;])print(soup.a)print(soup.find_all(&apos;a&apos;))print(soup.find(id=&apos;link3&apos;)) 使用Beautiful Soup解析这段代码，能够得到一个Beautiful Soup的对象，并能按照标准的缩进格式的结构输出。 同时我们通过下面代码可以分别获取所有的链接，以及文字内容：1234for link in soup.find_all(&apos;a&apos;): print(link.get(&apos;href&apos;))print(soup.get_text()) 解析器BeautifulSoup支持python标准库中的Html解析器，还支持一些第三方的解析器，如果我们不安装它，则python会使用python默认的解析器，lxml解析器更加强大，速度更快，推荐安装。 常见解析器：python标准库，lxml html解析器，lxml xml解析器, html5lib解析器 安装1pip install lxml 基本使用标签选择器 在快速使用中我们添加如下代码：1234print(soup.title)print(type(soup.title))print(soup.head)print(soup.p) 通过这种soup.标签名，我们就可以获得这个标签的内容 这里有个问题需要注意，通过这种方式获取标签，如果文档中有多个这样的标签，返回的结果是第一个标签的内容，如上面我们通过soup.p获取p标签，而文档中有多个p标签，但是只返回了第一个p标签内容。 获取名称 当我们通过soup.title.name的时候就可以获得该title标签的名称，即title 获取属性12print(soup.p.attrs[&apos;class&apos;])print(soup.p[&apos;class&apos;])上面两种方式都可以获取P标签的class属性值获取内容1print(soup.p.string)结果就可以获取第一个P标签的内容：The Dormouse’s story嵌套选择 我们可以直接通过下面嵌套的方式获取1print(soup.head.title.string) 子节点和子孙节点 contents的使用 通过下面例子演示1234567891011121314151617181920212223html = &quot;&quot;&quot;&lt;html&gt; &lt;head&gt; &lt;title&gt;The Dormouse&apos;s story&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class=&quot;story&quot;&gt; Once upon a time there were three little sisters; and their names were &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt; and they lived at the bottom of a well. &lt;/p&gt; &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;&quot;&quot;&quot;from bs4 import BeautifulSoupsoup = BeautifulSoup(html,&apos;lxml&apos;)print(soup.p.contents) 结果是将p标签下的所有子标签存入到了一个列表中 children的使用 通过下面的方式也可以获取p标签下的所有子节点内容和通过contents获取的结果是一样的，但是不同的地方是soup.p.children是一个迭代对象，而不是列表，只能通过循环的方式获取所有的信息。 123print(soup.p.children)for i,child in enumerate(soup.p.children): print(i,child) 通过contents以及children都是获取子节点，如果想要获取子孙节点可以通过descendantsprint(soup.descendants)同时这种获取的结果也是一个迭代器 父节点和祖先节点 通过soup.a.parent就可以获取父节点的信息 通过list(enumerate(soup.a.parents))可以获取祖先节点，这个方法的返回结果是一个列表，会分别将 a标签的父节点信息存放到列表中，以及父节点的父节点也放到列表中，并且最后还会将真个文档存放到列表中 所有列表的最后一个元素以及倒数第二个元素都是存的整个文档的信息。 兄弟节点 1234print(soup.a.next_siblings)#获取后面的兄弟节点print(soup.a.previous_siblings)#获取前面的兄弟节点print(soup.a.next_sibling)#获取下一个兄弟标签print(soup.a.previous_sibling)#获取上一个兄弟标签 标准选择器 find_all1find_all(name,attrs,recursive,text,**kwargs)可以根据标签名，属性，内容查找文档 name的用法 12345678910111213141516171819202122html=&apos;&apos;&apos;&lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;&apos;&apos;&apos;from bs4 import BeautifulSoupsoup = BeautifulSoup(html, &apos;lxml&apos;)print(soup.find_all(&apos;ul&apos;))print(type(soup.find_all(&apos;ul&apos;)[0])) 结果返回的是一个列表的方式 同时我们是可以针对结果再次find_all,从而获取所有的li标签信息 12for ul in soup.find_all(&apos;ul&apos;): print(ul.find_all(&apos;li&apos;)) attrs 例子如下：12345678910111213141516171819202122html=&apos;&apos;&apos;&lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;ul class=&quot;list&quot; id=&quot;list-1&quot; name=&quot;elements&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;&apos;&apos;&apos;from bs4 import BeautifulSoupsoup = BeautifulSoup(html, &apos;lxml&apos;)print(soup.find_all(attrs=&#123;&apos;id&apos;: &apos;list-1&apos;&#125;))print(soup.find_all(attrs=&#123;&apos;name&apos;: &apos;elements&apos;&#125;)) attrs可以传入字典的方式来查找标签，但是这里有个特殊的就是class,因为class在python中是特殊的字段，所以如果想要查找class相关的可以更改attrs={‘class_’:’element’}或者soup.find_all(‘’,{“class”:”element})，特殊的标签属性可以不写attrs，例如id text 例子如下： 123456789101112131415161718192021html=&apos;&apos;&apos;&lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;&apos;&apos;&apos;from bs4 import BeautifulSoupsoup = BeautifulSoup(html, &apos;lxml&apos;)print(soup.find_all(text=&apos;Foo&apos;)) 结果返回的是查到的所有的text=’Foo’的文本 find123456789find(name,attrs,recursive,text,**kwargs)find返回的匹配结果的第一个元素其他一些类似的用法：find_parents()返回所有祖先节点，find_parent()返回直接父节点。find_next_siblings()返回后面所有兄弟节点，find_next_sibling()返回后面第一个兄弟节点。find_previous_siblings()返回前面所有兄弟节点，find_previous_sibling()返回前面第一个兄弟节点。find_all_next()返回节点后所有符合条件的节点, find_next()返回第一个符合条件的节点find_all_previous()返回节点后所有符合条件的节点, find_previous()返回第一个符合条件的节点* CSS选择器通过select()直接传入CSS选择器就可以完成选择.表示class #表示id标签1，标签2 找到所有的标签1和标签2标签1 标签2 找到标签1内部的所有的标签2[attr] 可以通过这种方法找到具有某个属性的所有标签[atrr=value] 例子[target=_blank]表示查找所有target=_blank的标签123456789101112131415161718192021222324html=&apos;&apos;&apos;&lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;&apos;&apos;&apos;from bs4 import BeautifulSoupsoup = BeautifulSoup(html, &apos;lxml&apos;)print(soup.select(&apos;.panel .panel-heading&apos;))print(soup.select(&apos;ul li&apos;))print(soup.select(&apos;#list-2 .element&apos;))print(type(soup.select(&apos;ul&apos;)[0])) 获取内容 通过get_text()就可以获取文本内容 12345678910111213141516171819202122html=&apos;&apos;&apos;&lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;&apos;&apos;&apos;from bs4 import BeautifulSoupsoup = BeautifulSoup(html, &apos;lxml&apos;)for li in soup.select(&apos;li&apos;): print(li.get_text()) 获取属性 或者属性的时候可以通过[属性名]或者attrs[属性名] 1234567891011121314151617181920212223html=&apos;&apos;&apos;&lt;div class=&quot;panel&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;&apos;&apos;&apos;from bs4 import BeautifulSoupsoup = BeautifulSoup(html, &apos;lxml&apos;)for ul in soup.select(&apos;ul&apos;): print(ul[&apos;id&apos;]) print(ul.attrs[&apos;id&apos;])]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[正则表达式（五）]]></title>
    <url>%2F2020%2F09%2F01%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[正则表达式是对字符串操作的一种逻辑公式，就是事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符”，这个“规则字符”来表达对字符的一种过滤逻辑正则并不是python独有的，其他语言也都有正则。python中的正则，封装了re模块. 匹配字符串的几个方法123456789101112131415161718import res = &apos;besttest is good&apos;print(re.match(&apos;best&apos;, s))# match方法接收3个参数，第一个是匹配的规则，也就是正则表达式，第二个是要查找的字符串，# 第三个参数不是必填的，用于控制正则表达式的匹配方式，看下面正则表达式的匹配模式。是从字符串的第一个单词中匹配字符串，如果匹配到返回一个对象，如果匹配不到，则返回None# &gt;&gt;&gt;&lt;_sre.SRE_Match object; span=(0, 4), match=&apos;best&apos;&gt;print(re.search(&apos;best&apos;, s))# search方法的参数和match一样，和match方法不一样的是，match是从字符串里面的第一个单词里面找，而search方法则是从字符串的整个内容里面找，如果找到了就返回第一个，找不到就返回None# &gt;&gt;&gt; &lt;_sre.SRE_Match object; span=(0, 4), match=&apos;best&apos;&gt;print(re.findall(&apos;best&apos;, s))# findall方法的参数上面的match、search一样，和他们不一样的是，findall会返回所有一个list，把所有匹配到的字符串，放到这个list里面，如果找不到的话，就返回一个空的list# &gt;&gt;&gt; [&apos;best&apos;]print(re.sub(&apos;best&apos;, &apos;Best&apos;, s))# sub方法和字符串的replace方法一样，是用来替换字符串的，把匹配到的值替换成一个新的字符串，接收3个参数，第一个是正则表达式，第二个是要替换成什么，第三个就是要查找的字符串，会返回一个新的字符串，如果匹配不到的话，返回原来的字符串# &gt;&gt;&gt; Besttest is goodprint(re.split(&apos;best&apos;, s))# split 方法和字符串的split方法一样，是用来分割字符的，按照匹配到的字符串进行分割，返回的是一个list，如果匹配不到的话，那返回的list中还是原来的字符串# &gt;&gt;&gt; [&apos;&apos;, &apos;test is good&apos;] 常用正则表达式符号 1.数量词 123456789101112131415import re#&apos;*&apos; 匹配*号前的字符0次或多次，只是*前面的一个字符print(re.findall(r&apos;be*&apos;,&apos;besttest very best&apos;))# [&apos;be&apos;]#&apos;+&apos; 匹配前一个字符1次或多次，只是+前面的一个字符print(re.findall(r&apos;st+&apos;,&apos;besttest is best&apos;))#[&apos;stt&apos;, &apos;st&apos;, &apos;st&apos;]#&apos;?&apos; 匹配前一个字符1次或0次,只是?前面的一个字符print(re.findall(r&apos;st?&apos;,&apos;besttest is best&apos;))#&apos;&#123;m&#125;&apos; 匹配前一个字符m次print(re.findall(r&apos;t&#123;2&#125;&apos;,&apos;besttest is best&apos;))#[&apos;tt&apos;]#&apos;&#123;n,m&#125;&apos; 匹配前一个字符n到m次print(re.findall(r&apos;t&#123;1,2&#125;&apos;,&apos;besttest is best&apos;))# [&apos;tt&apos;, &apos;t&apos;, &apos;t&apos;] 2.一般字符串 123456789101112131415161718import re# &apos;.&apos; 默认匹配除\n之外的任意一个字符print(re.findall(r&apos;b.&apos;,&apos;besttest is good&apos;))# &apos;[....]&apos;,字符集合，# &gt;&gt;&gt; [&apos;be&apos;]# &gt;&gt;&gt; [&apos;st&apos;, &apos;st&apos;, &apos;s&apos;, &apos;st&apos;]# &apos;\&apos; 转译符，前面的* + ?这样的字符都有特殊含义了，如果你想就想找它的话，那就得转译了# 意思就是说如果你想让特殊字符失去以前的含义，那么就得给它前面加上\print(re.findall(r&apos;\?&apos;,&apos;besttest is best????&apos;))# &gt;&gt;&gt; [&apos;?&apos;, &apos;?&apos;, &apos;?&apos;, &apos;?&apos;]# &apos;|&apos; 匹配|左或|右的字符print(re.findall(r&apos;best|is&apos;,&apos;besttest is best&apos;))# &gt;&gt;&gt; [&apos;best&apos;, &apos;is&apos;, &apos;best&apos;]# &apos;[]&apos; 字符集合，某些字符的集合，匹配的时候是这个集合里面的任意一个就行print(re.findall(r&apos;be[stacj]&apos;,&apos;besttest is best bejson&apos;))# &gt;&gt;&gt;[&apos;bes&apos;, &apos;bes&apos;, &apos;bej&apos;]# 在[]里面如果用^的话代表取反，也就是不包括的这些字符串的print(re.findall(r&apos;be[^stac]&apos;,&apos;besttest is best bejson&apos;)) 3.边界匹配 1234567891011121314151617import re# &apos;^&apos; 匹配以什么字符开头,多行情况下匹配每一行的开头print(re.findall(r&apos;^b&apos;,&apos;besttest is good&apos;))# &gt;&gt;&gt; [&apos;b&apos;]print(re.findall(r&apos;^b&apos;,&apos;besttest is good\nbest&apos;,re.M))#多行模式# &gt;&gt;&gt; [&apos;b&apos;,&apos;b&apos;]# &apos;$&apos; 匹配以什么字符结尾,多行情况下匹配每一行的结尾print(re.findall(r&apos;d$&apos;,&apos;besttest is good&apos;))# &gt;&gt;&gt; [&apos;d&apos;]print(re.findall(r&apos;d$&apos;,&apos;besttest is good\nbest is good&apos;,re.M))#多行模式# &gt;&gt;&gt;[&apos;d&apos;,&apos;d&apos;]# &apos;\A&apos; 仅以什么字符开头，和^不同的是它不能用多行模式print(re.findall(r&apos;\Ab&apos;,&apos;besttest is good&apos;))# &gt;&gt;&gt; [&apos;b&apos;]# &apos;\Z&apos; 仅以什么字符结尾，和$不同的是它不能用多行模式print(re.findall(r&apos;d\Z&apos;,&apos;besttest is good&apos;))# &gt;&gt;&gt; [&apos;d&apos;] 4.预定义字符集合 12345678910111213141516171819import re# &apos;\d&apos; 匹配数字0-9print(re.findall(r&apos;\d+&apos;,&apos;sdf2342312sdfs&apos;))# &gt;&gt;&gt; [&apos;2342312&apos;]# &apos;\D&apos; 匹配非数字print(re.findall(r&apos;\D&apos;,&apos;sdf2342312sdfs&apos;))# &gt;&gt;&gt;[&apos;sdf&apos;, &apos;sdfs&apos;]# &apos;\w&apos; 匹配[A-Za-z0-9],也就是所有的字母和数字print(re.findall(r&apos;\w&apos;,&apos;sdf234%^2312sdfs&amp;&apos;))# &gt;&gt;&gt;[&apos;sdf234&apos;, &apos;2312sdfs&apos;]# &apos;\W&apos; 匹配不是[A-Za-z0-9]，也就是不是字母和数字print(re.findall(r&apos;\W&apos;,&apos;sdf234%^2312sdfs&amp;&apos;))# &gt;&gt;&gt;[&apos;%&apos;, &apos;^&apos;, &apos;&amp;&apos;]# &apos;\s&apos; 匹配空白字符、\t、\n、\r,空格print(re.findall(&apos;\s&apos;,&apos;axss\n\tsdf\t\r\t&apos;))# &gt;&gt;&gt; [&apos;\n&apos;, &apos;\t&apos;, &apos;\t&apos;, &apos;\r&apos;, &apos;\t&apos;]# &apos;\S&apos;匹配空白字符,不是\t、\n、\r,空格print(re.findall(&apos;\s&apos;,&apos;axss\n\tsdf\t\r\t&apos;))# &gt;&gt;&gt;[&apos;\n&apos;, &apos;\t&apos;, &apos;\t&apos;, &apos;\r&apos;, &apos;\t&apos;] 5.分组匹配 1234567891011121314import re# &apos;(...)&apos; 分组匹配，把某些规则写成在一个组里，这样就可以直接对这个进行一些匹配了，举个例子的话，如果要匹配ip地址的话# ip地址是类似这样的192.168.5.1，每一位都是1位或者3位的数字然后后面有个点正常写的话,得这么写print(re.findall(r&apos;\d&#123;1,3&#125;.\d&#123;1,3&#125;.\d&#123;1,3&#125;.\d&#123;1,3&#125;&apos;,&quot;192.168.1.3&quot;))# &gt;&gt;&gt; [&apos;192.168.1.3&apos;]# 这样写的话，有点麻烦了，通过上面的我们可以发现规律，除了第一个后面的全都是&apos;.\d&#123;1,3&#125;&apos;，写重复的代码就是低级的，这样的话就可以用分组了# 就把&apos;.\d&#123;1,3&#125;&apos;当做一个整体，然后让他们出现3次就ok了，可以改成下面这样的print(re.search(r&apos;\d&#123;1,3&#125;(.\d&#123;1,3&#125;)&#123;3&#125;&apos;,&quot;192.168.1.3&quot;).group())#这个是用search方法的，结果和上面的一样的# &gt;&gt;&gt; 192.168.1.3print(re.findall(r&apos;\d&#123;1,3&#125;(.\d&#123;1,3&#125;)&#123;3&#125;&apos;,&quot;192.168.1.3&quot;))#咱们继续用findall方法，发现结果是下面的# &gt;&gt;&gt; [&apos;.3&apos;]# 为啥会这样呢，用match方法和search方法都是正常的，findall方法这里有个坑，就是如果findall方法里面有分组的话，那结果就只是分组里面的内容# ，如果想让结果正确的话就在分组最前面写上&apos;?:&apos;，一个问号和一个冒号就好了，启用“不捕捉模式”print(re.findall(r&apos;\d&#123;1,3&#125;(?:.\d&#123;1,3&#125;)&#123;3&#125;&apos;,&quot;192.168.1.3&quot;))]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[requests模块使用（四）]]></title>
    <url>%2F2020%2F08%2F31%2Frequests%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[爬虫的原理就是写代码自动化的获取数据，保存下来数据，那怎么写代码来请求一个网址，获取结果，就要用到requests模块了。requests模块是python的一个第三方的模块，它是基于python自带的urllib模块封装的，用来发送http请求和获取返回的结果。安装requests1pip install requests requests模块用法123456789import requestsresponse=requests.get(&quot;http://www.baidu.com&quot;)print(type(response))print(response.status_code)print(type(response.text))print(response.text)print(response.cookies)print(response.content)print(response.content.decode(&quot;utf-8&quot;)) 我们可以看出response使用起来确实非常方便，这里有个问题需要注意一下：很多情况下的网站如果最直接response.text会出现乱码问题，所以这个使用response.content这样返回的数据格式其实是二进制格式，然后通过decode()转换为utf-8，这样就解决了通过response.text直接返回显示乱码的问题。 请求发出后，requests会基于HTTP头部对响应的编码作出有根据的推测。当你访问response.text之时，requests会使用其推测的文本编码。你可以找出Requests使用了什么编码，并且能够使用response.encoding属性来改变它。如：1234import requestsresponse=requests.get(&quot;http://www.baidu.com&quot;)response.encoding=&quot;utf-8&quot;print(response.text) 不管是通过response.content.decode(“utf-8”)的方式还是通过response.encoding=”utf-8”的方式都可以避免乱码问题的发生。 各种请求方式requests里提供各种请求方式123456import requestsrequests.post(&quot;http://httpbin.org/post&quot;)requests.put(&quot;http://httpbin.org/post&quot;)requests.delete(&quot;http://httpbin.org/post&quot;)requests.head(&quot;http://httpbin.org/post&quot;)requests.options(&quot;http://httpbin.org/post&quot;) 请求基本GET请求123import requestsresponse=requests.get(&quot;http://httpbin.org/get&quot;)print(response.text) 带参数的GET请求，例子1123import requestsresponse=requests.get(&quot;http://httpbin.org/get?name=Marry&amp;age=23&quot;)print(response.text) 如果我们想要在URL查询字符串传递数据，通常我们会通过http://httpbin.org/get?key=value方式传递。requests模块允许使用params关键字传递参数，以一个字典来传递这些参数，例子如下：12345678import requestsdata=&#123;&quot;name&quot;:&quot;Marry&quot;,&quot;age&quot;:23&#125;response=requests.get(&quot;http://httpbin.org/get&quot;,params=data)print(response.url)print(response.text) 上述两种的结果是相同的，通过params参数传递一个字典内容，从而直接构造url注意：第二种方式通过字典的方式的时候，如果字典中的参数为None则不会添加到url上 解析JSON1234567import requestsimportjsonresponse=requests.get(&quot;http://httpbin.org/get&quot;)print(type(response.text)) ----&gt;&lt;class &apos;str&apos;&gt;print(response.json())print(json.loads(response.text))print(type(response.json()))----&gt;&lt;class &apos;dict&apos;&gt; 从结果可以看出request里面集成的json其实就是执行了json.loads()方法，两者的结果是一样的 获取二进制数据在上面提到了response.content，这样获取的数据是二进制数据，同样的这个方法也可用于下载图片以及视频资源 添加headers和前面我们将urllib模块的时候一样，我们同样可以定制headers的信息，如当我们直接通过requests请求知乎网站的时候，默认是无法访问的123import requestsresponse=requests.get(&quot;https://www.zhihu.com&quot;)print(response.text) 这样会得到如下错误：因为访问知乎需要头部信息，这个时候我们在谷歌浏览器里输入chrome://version/ 就可以看到用户代理，将用户代理添加到头部信息。123456import requestsheaders=&#123;&apos;User-Agent&apos;:&apos;Mozilla/5.0(WindowsNT6.1;Win64;x64)AppleWebKit/537.36(KHTML,likeGecko)Chrome/85.0.4183.83Safari/537.36&apos;&#125;response=requests.get(&quot;https://www.zhihu.com&quot;,headers=headers)print(response.text) 这样就可以正常访问知乎了。 基本的POST请求通过在发送POST请求时添加一个data参数，这个data参数可以通过字典构造成，这样对于发送post请求就非常方便。1234567import requestsdata=&#123;&quot;name&quot;:&quot;Marry&quot;,&quot;age&quot;:23&#125;response=requests.post(&quot;http://httpbin.org/post&quot;,data=data)print(response.text) 同样在发送POST请求的时候也可以和发送get请求一样通过headers参数传递一个字典类型的数据。 响应我们可以通过response获得很多属性，例子如下1234567import requestsresponse=requests.get(&quot;http://www.baidu.com&quot;)print(type(response.status_code),response.status_code)print(type(response.headers),response.headers)print(type(response.cookies),response.cookies)print(type(response.url),response.url)print(type(response.history),response.history) 结果如下:状态码判断1234import requestsresponse=requests.get(&quot;http://www.baidu.com&quot;)ifresponse.status_code==requests.codes.ok:print(&quot;访问成功&quot;) requests高级用法文件上传实现方法和其他参数类似，也是构造一个字典后通过files参数传递1234import requestsfiles=&#123;&quot;files&quot;:open(&quot;m.jpg&quot;,&quot;rb&quot;)&#125;response=requests.post(&quot;http://httpbin.org/post&quot;,files=files)print(response.text) 获取cookie12345import requestsresponse=requests.get(&quot;http://www.baidu.com&quot;)print(response.cookies)forkey,valueinresponse.cookies.items():print(key+&quot;=&quot;+value) 会话维持Cookie的一个作用就是可用于模拟登陆，做会话维持12345import requestss=requests.Session()s.get(&quot;http://httpbin.org/cookies/set/number/123456&quot;)response=s.get(&quot;http://httpbin.org/cookies&quot;)print(response.text)]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HTTP请求（三）]]></title>
    <url>%2F2020%2F08%2F30%2FHTTP%E8%AF%B7%E6%B1%82%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[爬虫就是发送http请求（浏览器里面打开发送的都是http请求），然后获取到response，咱们再从response里面找到想要的数据，存储到本地。接下来就说一下什么是http请求，它里面都有哪些东西，我们在写爬虫的时候，怎么http请求，里面哪些对我们的爬虫有影响。 http请求过程咱们打开一个网站的时候，过程是这样的客户端（浏览器）发送请求到服务端（你打开的网站所在的服务器），服务端接收到请求，处理，返回数据给客户端（浏览器），然后在浏览器里面看到了数据。 请求方式主要有：GET/POST两种类型常用，另外还有HEAD/PUT/DELETE/OPTIONSGET和POST的区别就是：请求的数据GET是在url中，POST则是存放在请求体里面。 GET:一般向服务器获取数据用get请求，get请求的数据都是放在url中的，实质上和post请求没有太大的区别，当然也可以用来向服务器发送数据。 POST:一般向服务器发送数据用post请求，post请求的数据放在请求体里。 HEAD：与GET方法一样，都是向服务器发出指定资源的请求。只不过服务器将不传回资源的本文部分。它的好处在于，使用这个方法可以在不必传输全部内容的情况下，就可以获取其中“关于该资源的信息”（元信息或称元数据）。 PUT：向指定资源位置上传其最新内容。 OPTIONS：这个方法可使服务器传回该资源所支持的所有HTTP请求方法。用’*’来代替资源名称，向Web服务器发送OPTIONS请求，可以测试服务器功能是否正常运作。 DELETE：请求服务器删除Request-URI所标识的资源。 请求urlURL，即统一资源定位符，也就是我们说的网址，统一资源定位符是对可以从互联网上得到的资源的位置和访问方法的一种简洁的表示，是互联网上标准资源的地址。互联网上的每个文件都有一个唯一的URL，它包含的信息指出文件的位置以及浏览器应该怎么处理它。 URL的格式由三个部分组成： 第一部分是协议(或称为服务方式)。 http/https 第二部分是存有该资源的主机IP地址(有时也包括端口号)。 第三部分是主机资源的具体地址，如目录和文件名等。 /index 爬虫爬取数据时必须要有一个目标的URL才可以获取数据，因此，它是爬虫获取数据的基本依据。 请求头一个请求由两部分组成， 请求头和请求体。 包含请求时的头部信息，如User-Agent,Host,Cookies等信息，user-agent就是你请求用的是什么浏览器，host就是服务端的地址，还有很多信息，服务端是如何分辨你是用的什么浏览器，你的ip地址就是从请求头里面获取到的。 请求体请求体就是发送数据的时候，数据放在请求体里面。get请求是没有请求体的，post请求才有请求体。 http响应发送了请求，服务端要给返回数据。这个就是响应，请求是你发出去的，响应是服务端返回给你的。 响应包含了2个部分，一个是响应头，一个是响应体。响应头里面包含了响应的状态码，返回数据的类型，类型的长度，服务器信息，Cookie信息等等。 响应体里面就是具体返回的数据了。 响应状态码有很多响应状态，不同的状态码代表不同的状态，常见的状态码如：200代表成功，301跳转，404找不到页面，502服务端错误 1xx消息——请求已被服务器接收，继续处理 2xx成功——请求已成功被服务器接收、理解、并接受 3xx重定向——需要后续操作才能完成这一请求 4xx请求错误——请求含有词法错误或者无法被执行 5xx服务器错误——服务器在处理某个正确请求时发生错误 常见代码： 200 OK 请求成功 400 Bad Request 客户端请求有语法错误，不能被服务器所理解 401 Unauthorized 请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden 服务器收到请求，但是拒绝提供服务 404 Not Found 请求资源不存在 503 Server Unavailable 服务器当前不能处理客户端的请求，一段时间后可能恢复正常 301 目标暂时性转移 302 目标永久性转移]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[爬虫介绍（二）]]></title>
    <url>%2F2020%2F08%2F29%2F%E7%88%AC%E8%99%AB%E4%BB%8B%E7%BB%8D%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[一、什么是爬虫?爬虫：爬虫就是请求网站并提取数据的自动化程序。其中请求、提取、自动化是爬虫的关键。百科：网络爬虫（又称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。 二、爬虫可以干什么?爬虫可以帮你爬到你想要的东西，比如说你想要下载某个网站上面的图片、小视频、文章、文件，或者说你们公司想获取到对手公司网站上的一些数据用来分析市场，或者想要获取某一类网站用户的行为，用来分析用户以后的走向，都可以用爬虫来获取到数据。再比如说你想要做个什么内容类的app，类似今日头条的，那它里面的这些内容从哪里来的，它就是用爬虫、爬各种网站上热点新闻、八卦信息等等，再经过自己的加工放给用户去看。 三、爬虫的原理和实质:要从一个网站下载一个图片的话怎么办，要浏览器里面打开这个网站，然后右键保存图片到本地。那爬虫呢，就是写代码把上面的这个过程自动化，自动做这个操作，不需要在手动点了。这就是爬虫的原理。那爬虫的实质呢，就是写代码发http请求（浏览器里面打开发送的都是http请求），然后获取到response，咱们再从response里面找到想要的数据，存储到本地。 四、爬虫协议是什么？ 爬虫协议就是你想用爬虫爬我的网站，那么你得听我的，哪些你能爬，哪些你不能爬。 爬虫协议也称作Robots协议、机器人协议等，它的全称是“网络爬虫排除标准”（Robots Exclusion Protocol） 怎么查看一个网站的爬虫协议呢，就是在这个网站的域名后面加上robots.txt 比如说下面有：jd、百度、淘宝的爬虫协议 jd：https://www.jd.com/robots.txt 淘宝的：https://www.taobao.com/robots.txt 百度的：https://www.baidu.com/robots.txt 如果你要爬的网站域名加上robots.txt是404，那你就可以随心所欲的爬了。但是我们还是应该做一个“遵纪守法”的好爬虫。 爬虫协议里面有这么几个字段： User-agent：这个字段的意思是允许哪个引擎的爬虫获取数据 代表所有类型的爬虫都可以Disallow:/admin/这个字段代表爬虫不允许爬哪个路径下面的数据，如果是/的话，就代表所有的路径下面的数据都不能爬。 五、什么是反爬虫因为会有一些恶意的人，恶意的去用爬虫爬咱们的系统，获取一些数据用来做一些不好的事情，这样就会对我们的网站造成伤害。 那么反爬虫就是干这个事的，网站后台有程序专门检测发这个请求是爬虫发的，还是用户的正常请求（发请求就是打开一个页面），如果是爬虫发的话，那么就不给它返回数据，这就是返爬虫。当然有反爬虫那就有反爬虫的策略，就是看谁技术高低的问题了。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Windows安装Scrapy（一）]]></title>
    <url>%2F2020%2F08%2F28%2FWindows%E5%AE%89%E8%A3%85Scrapy%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Scrapy是python开发的一个爬虫框架;Scrapy很多模块都是基于Linux下的，所以在Windows上面安装的时候，可能会有各种各样的问题。 1.直接安装pip install scrapy 2.安装的时候scrapy它要依赖很多模块，一般都是其他的模块会报错。 3.在pip安装scrapy的时候，他会自动安装其他依赖的模块，安装到哪个模块报错了，它会停止安装。 4.查看报错模块缺少的是哪个依赖模块在进行安装即可。根据自己的情况来。 如：我安装的时候依赖缺少twisted库，即安装twisted库再安装scrapy twisted库不能通过pip 进行安装，可通过whl文件进行安装。进入：https://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted cp后面代表python版本，win后为计算机位数。需依据自己的情况选择合适的下载。 123456789101112131415**Twisted: an event-driven networking engine.**Twisted-20.3.0-cp39-cp39-win amd64.whl Twisted-20.3.0-cp39-cp39-win32.whl Twisted-20.3.0-cp38-cp38-win amd64.whl Twisted-20.3.0-cp38-cp38-win32.whl Twisted-20.3.0-cp37-cp37m-win amd64.whl Twisted-20.3.0-cp37-cp37m-win32.whl Twisted-20.3.0-cp36-cp36m-win amd64.whl Twisted-20.3.0-cp36-cp36m-win32.whl Twisted-19.10.O-cp35-cp35m-win amd64.whl Twisted-19.10.O-cp35-cp35m-win32.whl Twisted-19.10.O-cp27-cp27m-win amd64.whl Twisted-19.10.o-cp27-cp27m-win32.whl Twisted-18.9.0-cp34zcp34m-win amd64.whl Twisted-18.9.0-cp34-cp34m-win32.whl 找到twisted库，下载到本地。下载好后，进入twisted刚刚下载所在的目录进行安装 我的电脑是win64位，python3.8的就下载这个Twisted‑20.3.0‑cp38‑cp38‑win_amd64.whl 安装：1pip install Twisted‑20.3.0‑cp38‑cp38‑win_amd64.whl]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework-断言函数]]></title>
    <url>%2F2020%2F08%2F15%2FRobot-Framework-%E6%96%AD%E8%A8%80%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[测试用例的目的是要验证一些操作否符合我们的预期结果，所以在测试用例中，断言函数是必不可少的一项。我们做的每一步操作都会有预期的结果，为了保证操作得到的结果符合预期，我们需要在测试用例中添加断言，来保证实际结果和预期结果一致。常用的断言函数： 1、should be equal 与should not be equal第一行设置一个变量并赋值为1，第二行变量${var}和1应该是相等的。运行：会发现只是打印出了变量的值，一般来说，断言函数只起断言作用，符合断言没有任何操作，不符合则会报错：现在我们把${var}值改为2，断言不变，再运行：得到结果2！=1，用例报红，并且这里给出了断言出错。 should not be equal恰好相反，用来断言不相等。 2、should be empty与should not be empty断言为空或不为空。如上图，Create List是一个创建列表的函数，我们没有为列表赋值，则${var}是一个空列表，运行：可以看到打出了预期的空列表，并且用例成功运行。should not be empty恰好相反，用来断言不为空。 3、should contain、should not contain与should contain x times这里先说明一下，列表变量也可以用@{var}表示，但${var}既可以表示单个变量，也可以表示列表，字典，用起来方便，我们创建了一个列表，内含a，b，c三个值，断言列表中含有a：运行通过，打印出了变量值，可以看到正如我们的预期，${var}是一个列表。should not contain恰好相反，断言为不包含。should contain x times根据英文翻译即可，就是应该含有某值x次：这里的断言意思是变量${var}中应该包含2个1，运行： 4、should be equal as numbers与should not be equal as numbers以number的形式来进行比较，示例：should not be equal as numbers相反，不应等于数字。 5、should be equal as integers与should not be equal as integers以整数的形式来进行比较，示例：should not be equal as integers相反，不应等于整数。 6、should be equal as strings与should not be equal as strings以字符串的形式来进行比较，示例：should not be equal as strings相反，不应与字符串相等。 7、should start with与should not start with判断某个字符串是否以预期执行的字符串开始，如果以指定的字符串开头，则执行成功，否则执行失败，示例：与Should Start With刚好相反，如果以指定的字符串开头，则执行失败，否则执行成功，示例： 8、should end with与should not end with判断某个字符串是否以预期执行的字符串结尾，如果以指定的字符串结尾，则执行成功，否则执行失败，示例：与Should End With刚好相反，如果以指定的字符串结尾，则执行失败，否则执行成功。 9、should match与should not match 判断某个字符串是否与预期指定的字符串相匹配，如果可以匹配，则执行成功，否则执行失败，示例：与Should Match刚好相反，如果字符串匹配，则执行失败，否则执行成功，示例：]]></content>
      <categories>
        <category>Robot Framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework-常用快捷键]]></title>
    <url>%2F2020%2F08%2F15%2FRobot-Framework-%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[robot framework常用快捷键，记录下来，下次使用不记得就不用百度了,需要注意一点，如果快捷键不能使用，先看看是否有其他软件已占用相应的快捷键。 重命名——》F2 搜索关键字——》F5 执行用例——》F8 创建新工程——》ctrl+n 创建新测试套——》ctrl+shift+f 创建新用例——》ctrl+shift+t 创建新关键字——》ctrl+shift+k 向上移动用例——》ctrl+↑ 向下移动用例——》ctrl+↓ 显示关键字信息——》 ctrl+鼠标悬浮（鼠标悬浮于关键字上） 自动补全关键字——》ctrl+shift+空格 删除行——》ctrl+d 删除单元格——》ctrl+shift+d 插入单元格——》ctrl+shift+i 插入行——》ctrl+i 屏蔽代码——》ctrl+# 取消屏蔽——》ctrl+$ 保存整个工程——》ctrl+shit+s 局部保存，保存鼠标点击的部分——》ctrl+s 查看log——》ctrl+L 查看report——》ctrl+r]]></content>
      <categories>
        <category>Robot Framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework-下拉列表]]></title>
    <url>%2F2020%2F08%2F14%2FRobot-Framework-%E4%B8%8B%E6%8B%89%E9%80%89%E6%8B%A9%E6%A1%86%2F</url>
    <content type="text"><![CDATA[下拉选择框很常见，选择下拉框有几种方式处理，首先在浏览器F12选择下拉框,F12后看见下拉框的源码是 option xxx，可使用Select From List By Index，Select From List By Label和Select From List By Label关键字1.Select From List By IndexArguments:[ locator | *indexes ]两个参数：一个是select元素的定位路径，一个是下拉选项的下标，从0开始，0表示选择第一个值。 2.Select From List By LabelArguments:[ locator | *lables]两个参数：一个是select元素的定位路径，一个是下拉选项的text值，注意是text值，不是标签的value值。 3.Select From List By ValueArguments:[ locator | *values]两个参数：一个是select元素的定位路径，一个是下拉选项的标签value值。 4.Click element直接定位到选择的元素 如果F12后看到的下拉源码是这样的： div xxxx ，使用下面方式 Click Element xpath = //xxx/div[2] #先点击下拉框显示出来 Click Element xpath=//xxx/xxx//div[text()=’用户A’] #然后再点击所要选择的下拉内容]]></content>
      <categories>
        <category>Robot Framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework--分层思想]]></title>
    <url>%2F2020%2F08%2F14%2FRobot-Framework-%E5%88%86%E5%B1%82%E6%80%9D%E6%83%B3%2F</url>
    <content type="text"><![CDATA[在Java中，程序设计讲究设计模式，设计模式其实就是根据需求使用抽象和封装，其实这个就是分层思想，把一个实现过程分成不同多层，提高灵活性，从而达到可扩展性和可维护性。要谈RF的分层思想，就不得不说到关键字驱动，刚刚我们介绍了关键字驱动：类似函数，通过调用不同的关键字，从而测试结果就不同。在RF中，我们可以把操作步骤封装一个一个的方法（关键字），通过调用关键字来实现测试用例。 比如我们要登录测试环境，创建下面的一条登录的测试用例。 现在我要写3条测试环境登录的用例： 可以在测试套件下创建3条测试用例，如果我们现在要检查登录，登陆不同的账号，其实只是输入的文本变了，而操作步骤和操作的元素都是不变的，如果这样做，无疑增加的脚本的冗余，而且不便于维护。假如，输入框的定位方式变了，我不得不打开每一条用例进行修改。 所以我们把一个个操作封装成关键字，放在一个专放操作的文件夹里，以便管理。需要用到是则去一一调用这些关键字，而不需要重复写这些步骤，从而实现分层的思想来解决这个问题。如下：右键“测试项目”选择“new resource”创建资源。输入资源名称：2、创建关键字右键“业务关键字”选择“new User Keyword” 来创建用户关键字。输入关键字的名称： 3、编辑关键字对于一个测试用例来说，用户关心的是输入什么内容，得到什么结果。所以，对于“登录”关键字来说，需要创建三个接口变量${mobile}，${password}和${result}三个变量，用于接收输入内容和预期结果。点击Arguments输入框，定义变量，多个变量从用“|”隔开。 在登录用户中使用参数化变量。 4、添加创建的资源切换到测试套件页面，添加资源（业务关键字.txt）5、调用关键字现在就可以在测试用例中使用创建的关键字了（登录页面）。对于每一条用例来说，调用“登录”关键字，输入手机号、密码，输入预期结果即可。不用关心用例是如何执行的。如果手机号码，密码输入框的定位发生了变化，只用去修改“登录”关键字即可，不用对每一条用例做任何修改。大大提高的用例的维护性和扩展性。 继续分层的设计： 为了以后维护更方便，可以再把元素定位分离出来，放在一个专放元素定位的文件夹里…如果以后页面发生了调整，我们就需要修改元素的定位，就不用一条条用例打开去修改，只要修改页面定位元素即可如下：]]></content>
      <categories>
        <category>Robot Framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework-FAIL For loop has no closing 'END']]></title>
    <url>%2F2020%2F08%2F13%2FFAIL-For-loop-has-no-closing-END%2F</url>
    <content type="text"><![CDATA[今天练习条件与循环跟着网上的例子执行循环时，一直执行不通过，写法都一样，一直报错FAIL For loop has no closing ‘END’ 最后发现输入:FOR时冒号自动消失了，于是打开F5查看了:FOR关键字，发现文档写着已经不赞成使用了，使用请查看FOR关键字.RIDE最新版本和之前的版本在用例脚本编写还是有一些差异存在的，如果冒号（:）丢失就要在FOR循环语句后加上END。 RIDE1.7.4.1版本的FOR循环语句结构与RIDE之前版本稍微有些变化，需要在FOR循环语句结束后加上END（注意END一定要大写）。 加上END后就可以运行成功了，正确用例脚本如下：]]></content>
      <categories>
        <category>问题+解决方法记录</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework-关键字]]></title>
    <url>%2F2020%2F08%2F13%2FRobot-Framework-Selenium2Library%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[关键字的使用可以通过F5查找关键字库，输入关键字，点击搜索。选择关键字就可以查看关键字的说明。如图： 1、浏览器驱动 通过不同的浏览器执行脚本 Open Browser https://www.baidu.com Chrome 常用浏览器对应的关键字 firefox Firefox chrome Chrome ie InternetExplorer safari Safari open browser 同样也可以打开本地html页面，如： Open Browser file:///D:/RFpath/js.html Chrome 备注：要想通过不同的浏览器打开url地址，一定要安装对应的驱动。chrome的驱动为：chromedriver.exefirefox的驱动为：geckodriver.exe…浏览器默认为空时启动FireFox 2、关闭浏览器 Close Browser Close All Browser Close Browser关闭当前的浏览器，Close All Browser 关闭所有打开的浏览器和缓存重置。 3、浏览器最大化 Maximize Browser Window 4、设置浏览器宽、高 Set Window Size 800 600 Set Window Size关键字，用于设置当前浏览器的宽度和高度，以像素为单位，第一个参数800表示宽度，第二个参数600表示高度。 Get Window Size关键字，用于获取当前浏览器的宽度和高度，获得浏览器的宽、高并打印，如下： 5、文本输入input text用于向文本框输入信息，id=KW表示元素定位，定位文本框输入 6、点击按钮 7、点击元素 8、等待页面元素出现 Wait Until Page Contains Element关键字用于等待页面上的元素显示出来。//*[@id=”container”]/div[2]/div/div[2]/span:表示元素定位，这里定位出现的元素60：表示最长等待时间error:表示错误提示，可以自己自定义错误提示 如：元素不能正常显示 9、获取title Get Title关键字用于获得当前浏览器窗口的title信息。Should Contain 比较${title}是否等于“robot_百度搜索”这里只获得title是没有意义的，我们通常会将获取的title传递给一个变量，然后与预期结果进行比较。从而判断当前脚本执行成功。 10、获取Text Get Text关键字用于获取元素的文本信息//*[@id=”container”]/div[2]/div/div[2]/span:表示定位文本信息的元素 11、获取元素属性值 id=kw 表示定位的元素name 表示获取这个元素的 name 属性值。 12、log 打印log关键字就是编程语言里的“print”一样，可以打印任何你想打印的内容。 13、定义变量通过”Set Variable”关键字来定义变量 14、连接对象“Catenate”关键字可以连接多个信息加上“SEPARATOR=”可以对多个连接的信息进行分割。 15、定义列表通过“Create List”关键字可以定义列表。每个字符串前面加 u，是为了统一编码问题，将字符串转为 Unicode 编码。如果通过“@{}”去定义列表的话，可以通过“log many”关键字进行打印 16、时间操作 Robot Framework 中提供了“get time”关键字用来获取当前时间。 17、设置休眠时间 “sleep”关键字用来设置休眠一定时间，sleep 关键字默认以“秒”为单位。 18、if语句 通过“run keyword if”关键字可以编写 if 分支语句。 首先定义一个变量 a 等于 59 。If 判断 a 大于等于 90 ，满足条件 log 输出 “优秀 ”；不满足上面的条件，接着 else if 判断 a 大于等于 70 ，满足条件 log 输出 “良好”；不满足上面的条件，接着 else if 判断 a 大于等于 60 ，满足条件 log 输出 “及格”；上面的条件都不满足，else log 输出“不及格”。注：注意 ELSE IF 和 ELSE 前面的三个点点点（…）。注意ELSE IF和ELSE要是大写。 19、for循环在 Robot Framework 中编写循环通过“for”。通过“：for”定义 for 循环；in range 用于指定循环的范围。例子1，这个例子为执行 10 次循环注意：in range 定义为 10，它的范围是 0~9例 2，遍历列表“create list” 关键字用来定义列表（a,b,c），“@{}”用来存放列表。通过“for”循环来来遍历@{abc}列表中的字符。20、 Evaluate生成随机数21、注释Robot Framework 中添加注释也非常简单。（1）“Comment”关键字用于设置脚本中的注释。（2）也可以像 Python 一样使用“#”号进行注释]]></content>
      <categories>
        <category>Robot Framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework -元素定位]]></title>
    <url>%2F2020%2F08%2F13%2FRobot-Framework-%E5%85%83%E7%B4%A0%E5%AE%9A%E4%BD%8D%2F</url>
    <content type="text"><![CDATA[1.id和name定位id、name定位，这两个比较简单直接可以id=和name=，前提是这个id和name的值在当前页面上是唯一的。12345…&lt;input id=&quot;kw&quot; name=&quot;wd&quot; class=&quot;s_ipt&quot; value=&quot;&quot; maxlength=&quot;255&quot; autocomplete=&quot;off&quot;&gt;…&lt;input type=&quot;submit&quot; id=&quot;su&quot; value=&quot;百度一下&quot; class=&quot;bg s_btn&quot;&gt;… 根据上面的例子，百度输入框可以提取id或name进行定位。 id=kw name=wd在Robot framework中可以这样写：Input Text 用于文本输入的关键字，“robot framework学习”是要给输入框输入的内容.百度按钮没有name，所以这里可以用id： id=suClick Button 是按钮点击的关键字。 2.Xpath定位Xpath是XML文档中定位元素的一种语言，HTML可以看成一种XML文档，Xpath定位也是所有定位元素的方法中用的最多的。Xpath 中的绝对路径从 HTML 根节点开始算，相对路径从任意节点开始。通过开发者工具，我们可以拷贝到 Xpath 的绝对路径和相对路径代码：但是由于拷贝出来的代码缺乏灵活性，也不全然准确。大部分情况下，都需要自己定义 Xpath 语句，因此 Xpath 语法还是有必要学习。 2.1绝对路径定位以百度中的输入框和按钮为例，通过拷贝出来的 full Xpath：1/html/body/div[1]/div[1]/div[5]/div/div/form/span[1]/input 这是一个绝对路径，绝对路径是从根节点/html开始往下找，html下面的body下面的div下面的第5个div下面的….input标签。通过一级一级的锁定就找到了想要的元素。 2.2相对路径定位除了绝对路径，Xpath中更常用的方式是相对路径定位方法，以“//”开头相对路径可以从任意节点开始，一般我们会选取一个可以唯一定位到的元素开始写，增加查找的准确性。 2.2.1元素属性定位Xpath可以利用元素自身的属性进行定位：1Xpath=//*[@id=’kw’] //表示某个层级下，*表示某个标签名。@id=kw 表示这个元素有个id等于kw（@ 符号指定需要使用的属性）也可以制定标签名1Xpath=//input[@id=”kw”] 元素本身，可以利用的属性不止局限于id和name,还可以使用其他属性，如：12Xpath=//input[@type=”text”]Xpath=//input[@autocomplete=&quot;off&quot;] 但是这些元素必须在这个页面是唯一的，否则定位时会出错。 2.2.2找上级遇到某些元素无法精确定位的时候，可以查找其父级及其祖先节点，找到有确定的祖先节点后通过层级依次向下定位。元素的上级属性为：123&lt;form id=&quot;form1&quot; class=&quot;fm&quot; action=&quot;/s&quot; name=&quot;f1&quot;&gt;&lt;span class=&quot;bg s_ipt_wr&quot;&gt;&lt;input id=&quot;kw&quot; class=&quot;s_ipt&quot; type=&quot;text&quot; maxlength=&quot;100&quot; name=&quot;wd&quot; autocomplete=&quot;off&quot;&gt; 找爸爸：1Xpath=//span[@class=” bg s_ipt_wr”]/input 如果爸爸没有唯一的属性，可以找爷爷：1Xpath=//from[@id=’from1]/span/input 这样一级一级找上去，直到html,那么就是一个绝对路径了 2.2.3使用逻辑运算符如果元素的某个属性无法精确定位到这个元素，我们还可以用逻辑运算符 and 连接多个属性进行定位，以百度输入框为例。1、 使用and:1//*[@name=&apos;wd&apos; and @class=&apos;s_ipt&apos;] 查找 name 属性为 wd 并且 class 属性为 s_ipt 的任意元素 2、 使用or:1//*[@name=&apos;wd&apos; or @class=&apos;s_ipt&apos;] 查找 name 属性为 wd 或者 class 属性为 s_ipt 的任意元素，取其中之一满足即可 3、使用|，同时查找多个路径，取或：1//form[@id=&quot;form&quot;]//span | //form[@id=&quot;form&quot;]//input 选取 form 下所有的 span 和所有的 input。 3.CSS定位CSS(Cascading Style Sheets)是一种语言，它被用来描述HTML 和XML 文档的表现。CSS 使用选择器来为页面元素绑定属性。CSS 可以比较灵活选择控件的任意属性，一般情况下定位速度要比XPath 快，但对于初学者来说比较难以学习使用，下面我们就详细的介绍CSS 的语法与使用。CSS 选择器的常见语法:同样以百度输入框的代码，我们来看看CSS如何定位。123&lt;form id=&quot;form1&quot; class=&quot;fm&quot; action=&quot;/s&quot; name=&quot;f1&quot;&gt; &lt;span class=&quot;bg s_ipt_wr&quot;&gt; &lt;input id=&quot;kw&quot; class=&quot;s_ipt&quot; type=&quot;text&quot; maxlength=&quot;100&quot; name=&quot;wd&quot; autocomplete=&quot;off&quot;&gt; id定位：1css=#kw class 定位：1css=.s_ipt 其他属性定位：123css=[name=wd]css=[type=text]css=[autocomplete=off] 父子定位：12Css=span&gt;inputCss=from&gt;span&gt;input 根据标签名定位：1Css=input 代码实现：]]></content>
      <categories>
        <category>Robot Framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework-[ ERROR ] Suite 'TestProject' contains no tests matching name]]></title>
    <url>%2F2020%2F08%2F12%2F%5B%20ERROR%20%5D%20Suite%20'TestProject'%20contains%20no%20tests%20matching%20name%2F</url>
    <content type="text"><![CDATA[编写用例完成，运行测试用例，运行完成报错：1[ ERROR ] Suite &apos;TestProject&apos; contains no tests matching name &apos;TestProject.TestSuites.baidu_search&apos; in suite &apos;TestProject.TestSuites&apos;. 如图： 原因：是由于在创建测试套件（test suite）时，格式选择为TXT文件格式导致 解决办法：将文件修改为robot格式即可。]]></content>
      <categories>
        <category>问题+解决方法记录</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework--第一个脚本]]></title>
    <url>%2F2020%2F08%2F12%2FRobot-Framework-%E7%AC%AC%E4%B8%80%E4%B8%AA%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[1.Robot Framework介绍Robot Framework的架构是一个通用的验收测试和验收测试驱动开发的自动化测试框架（ATDD）。它具有易于使用的表格来组织测试过程和测试数据。 它使用关键字驱动的测试方法。对于上面的例子来说，Open Browser、input text、click element、sleep、Get Title、Should Contain和close browser，都是“关键字”，这些关键字由robotframework-selenium2library类库所提供。当然我们也可以自定义关键字。Robot Framework的操作系统和应用独立框架。核心框架是使用Python和运行在Jython(JVM)和IronPython(.NET) 2.Robot Framework入门下面一步一步来创建我们的第一条用例 1.创建测试项目选择菜单栏file—-&gt;new Project, Name 输入项目名称,Type 选择Directory 2.创建测试套件右键点击“测试项目”选择new Suite选项，Name 输入项目名称，Type 选择File，Format选择ROBOT（如果选的是TXT格式，运行用例时会报错） 3.创建测试用例右键点击“测试套件”选择new Test Case,点击OK即可。 导入Selenium2Library库 因为RF框架编写基于web 的测试用例，所以，我们需要selenium 的库支持。所以，我们在使用的过程中需要加载Selenium2Library库 在“测试套件”的Edit标签页，点击“Library”按钮，弹出输入框，Name输入：Selenium2Library，点击OK完成。如果导入的库显示红色，表示导入的库不存在。如果是黑色则表示导入成功。注意区分大小写。 5.编写用例下面就可以写我们的用例了，可以通过F5快捷键来查询库提供的关键字。 如上图，自动化脚本从打开浏览器开始，我想打开一个浏览器，自然想到的是以“open”为关键字搜索，结果找到了“Open Browser”的关键字，点击这个关键字，显示它的用法和说明。下面开始实操创建百度搜索用例如下： “Open Browser”变蓝了，说明它是一个合法的关键字，后面有一个方框是红色的，表示这个参数不能缺省的。通过说明信息中，发现它需要一个url 地址是必填的，当然还需要指定browser （默认不填为 friefox） 6.运行测试用例勾选当前需要运行的测试用例，点击工具栏运行按钮，如果只运行单个用例的话，也可以切换到用例的Run标签页，点击“start”按钮。 运行信息： 运行信息显示会生成三个文件：Output.xml、Log.html、Report.html我们重点查看Log.html和Report.html ，Log.html更关注脚本的执行过程的记录，Report.html更关注脚本的执行结果的展示。]]></content>
      <categories>
        <category>Robot Framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework-python3.8与ride不兼容问题]]></title>
    <url>%2F2020%2F08%2F12%2Fpython3.8%E4%B8%8Eride%E4%B8%8D%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[robotframework环境搭建完成，运行ride报错 1、robotframework 环境（pip list）：python 3.8.2robotframework 3.2.1wxpython 4.0.7ride 1.7.4.2 2、运行ride报错 百度上找了一圈，有人说是robotframework-ride最新版本1.7.4.2 不兼容 python 3.8，后来把1.7.4.2版本的卸载了1pip uninstall robotframework 又重新指定版本安装1.7.4.1的试试看：1pip install robotframework-ride==1.7.4.1 终于装上了！ 然而又报了新的错误… 又继续百度说是系统语言的问题，在 robotide 中找到应用程序配置项Lib\site-packages\robotide\application\application.py，看到初始加载的语言环境是英文。 加上一个局部支持的语言试试 把修改application.py中 self._initial_locale = wx.Locale(wx.LANGUAGE_ENGLISH)改为：1self.locale = wx.Locale(wx.LANGUAGE_ENGLISH) 又出现了新的问题.. 这次报的是缩进的问题，源码缩进格式不正确，简单粗暴的复制下面没问题的源码缩进，终于终于运行能够打开了！]]></content>
      <categories>
        <category>问题+解决方法记录</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework-RIDE桌面快捷方式制作]]></title>
    <url>%2F2020%2F08%2F12%2FRobot%20Framework-RIDE%E6%A1%8C%E9%9D%A2%E5%BF%AB%E6%8D%B7%E6%96%B9%E5%BC%8F%E5%88%B6%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[接上一篇笔记0.0 1.创建快捷方式 在桌面右键鼠标，弹出的菜单选择 新建-快捷方式，然后在请键入对象的位置输入这一行命令 D:\Python38\pythonw.exe -c “from robotide import main; main()” 注：根据自己安装python的路径，我的是在D盘的，还有双引号记得是英文格式哦，否则会启动不了哦 如图： 点击下一步，输入快捷方式的名称，根据自己需要随意命名就好。 点击完成后会在桌面生成图标 2.如果想要把图标换成机器人图标需要快捷方式上点击右键-属性，如图 点击“更改图标”，在浏览里找到目录D:\Python38\Lib\site-packages\robotide\widgets，里面有个robot.ico的图标 选它就可以了，效果如图 最后快捷方式就制作完成了，可以打开正常使用了。]]></content>
      <categories>
        <category>Robot Framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Robot Framework环境搭建]]></title>
    <url>%2F2020%2F08%2F11%2FRobot%20Framework%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[1.Python3.8安装下载地址：https://www.python.org/downloads/release/python-381/ python-3.8.1.amd64.msi(python2官方已宣布到2020年元旦起不再维护，所以为了以后方便在这里安装python3) 下载完成后，选择安装路径自行安装即可。安装完成后注意配置系统环境变量path:配置Python38安装路径和Python38/Scripts路径。 2.Robot framework的安装RF框架是基于python的，所以一定要有python环境 安装方式选择一种即可： （1）exe包安装下载地址：https://pypi.org/project/robotframework/3.2.1/#downloads robotframework-3.2.1.win-amd64.exe 直接双击下一步即可。 （2）pip命令安装1pip install robotframework 这样子会直接安装最新的版本，我们可以指定版本安装pip install robotframework==3.2.1 3.wxPython 的安装作用：Wxpython 是python 非常有名的一个GUI库，因为RIDE 是基于这个库开发的，所以这个必须安装。 （1）exe包安装下载地址：http://sourceforge.net/projects/wxpython/files/wxPython/ 直接双击下一步即可。 （2）pip命令安装1pip install wxPython==4.0.7 在线安装 wxPython，最好指定版本安装，否则会直接安装最新的版本 （这个版本不能太低…太低不支持python3.8，太高也会报错…所以找了个版本不高，又支持3.8的wxPython==4.0.7） 4.Robot framework-ride作用：RIDE就是一个图形界面的用于创建、组织、运行测试的软件。 安装方式选一种即可： （1）包安装下载地址：https://pypi.python.org/pypi/robotframework-ride robotframework-ride-1.7.4.2.tar.gz 下载完成后将其解压，然后进入到解压后的文件路径进行安装123cd D:\robotframework-ride-1.7.4.2python setup.py install （2）pip安装1pip install robotframework-ride=1.7.4.1（安装了最新的1.7.4.2一直报错，所以我这里装的是1.7.4.1） 5.Robot framework-selenium2library作用：RF-seleniumlibrary 可以看做RF版的selenium 库，selenium （webdriver）可以认为是一套基于web的规范（API），所以，RF 、appium 等测试工具都可以基于这套API进行页面的定位与操作。 （1）包安装下载地址：https://github.com/robotframework/Selenium2Library#readme Selenium2Library-master.zip 下载完成后将其解压，然后进入到解压后的文件路径进行安装 12cd D:\Selenium2Library-masterpython setup.py install （2）pip安装1pip install robotframework-selenium2library 6.放入驱动以上步骤都已安装完毕后，把需要用的驱动放到python3的目录下，用谷歌浏览器较多，所以我把谷歌驱动文件chromedriver.exe放入我的python3安装目录D:\Python38 7.查看pybot版本12cd D:\Python38\Scriptspybot --version 8.启动RIDE 1.通过文件启动（双击D:\Python38\Lib\site-packages\robotide下的init.py文件） 2.通过命令启动（运行-&gt;ride.py回车/确认，打开ride.py文件之后（以python方式打开 ） 12cd D:\Python38\Scripts\python ride.py 3.将D:\Python38\Scripts\ride.py创建快捷键 注：根据自己的python安装路径，我的是在D盘的]]></content>
      <categories>
        <category>Robot Framework</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Jmeter断言]]></title>
    <url>%2F2020%2F01%2F19%2FJmeter%E6%96%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[Jmeter中有个元件叫做断言（Assertion），它的作用和loadrunner中的检查点类似；用于检查测试中得到的响应数据等是否符合预期，用以保证性能测试过程中的数据交互与预期一致。Jmeter里面的检查点通过添加断言来完成，上一章讲到，我们对用户名和密码进行了参数化，那么怎么来判断Jmeter有没有正确调用user.txt里面的文件呢，我们可以在登录这个地方添加断言来进行检查 1、 添加响应断言，右键点击要断言的那个接口—-&gt;添加—-&gt;断言—-&gt;响应断言 2、 设置响应断言 3、添加断言结果，右键点击登录接口—-&gt;添加—-&gt;监听器—-&gt;断言结果 再添加一个“察看结果树” 右键点击登录接口—-&gt;添加—-&gt;监听器—-&gt;察看结果树 在线程组中设置用户数量（我有6个用户，所以我的设置为6），点击运行. 4、查看断言结果 1)、断言成功，如下图： 2）、若断言失败，如下图： 注意：一般成功只会显示一行数据，否则会多显示一行。 5、再察看结果树 至此，检查点设置完成。]]></content>
      <categories>
        <category>Jmeter</category>
      </categories>
      <tags>
        <tag>Jmeter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jmeter参数化]]></title>
    <url>%2F2020%2F01%2F18%2FJmeter%E5%8F%82%E6%95%B0%E5%8C%96%2F</url>
    <content type="text"><![CDATA[Jmeter参数化的四种方法介绍： 一、CSV数据配置文件 在测试的过程中我们需要批量的随机性数据，比如测试登录需要用到大量的用户名及对应的密码，我们将需要的数据写在txt（或csv，dat）文件中，并在Jmeter中读取这个文件中的数据。 这里我新建一个user.txt文件，并用notepad++编辑工具打开编辑（文件编码格式为utf-8），编码问题在使用CSV Data Set Config参数化时要求的比较严格，按照JMeter读取csv文件的逻辑，每次读取一行参数，一行代表一组参数。 注意用户名和密码是一一对应的，中间用户逗号（,）隔开。 接下来在需要用到参数的接口上右键添加—配置元件–CSV数据文件设置 配置内容如下： 变量名称：待会调用时用到的名称忽略首行：是否忽略csv文件中的首行内容分隔符：一般使用英文逗号 1、使用变量 在需要使用的接口中，将参数值改为变量,变量名称为CSV数据文件设置里填写的变量名称。 2、设置线程数及循环次数 3、运行，察看结果树，整个参数化过程完成。 二、借助函数助手的方式： 点击菜单栏“Tools”–&gt;函数助手对话框， 复制生成的参数化函数，打开要使用参数化的接口页面，找到我们要参数化的字段，这里对用户名和密码做参数化，第一列是用户名，列号为0；第二列是密码，列号为1；修改函数中对应的参数化字段列号就可以啦。 好了，现在我们的参数化设置完成，在脚本的时候，会调用我们D:\apache-jmeter-5.1.1盘下面的user.txt文件，第一列是用户名，第二列是密码。运行，察看结果树，即可和上面操作的结果一致。 三、用户参数添加-前置处理器-用户参数可以添加多个变量或者参数 四、用户自定义变量 线程组右键添加—配置元件—用户定义的变量 以上就是jmeter参数化的四种方式，其中：1、 CSV Data Set Config:CSV配置文件，适用于参数取值范围较大的时候使用，该方法具有更大的灵活性；2、 函数助手_CSVRead的参数化，功能相比CSV Data Set Config较弱；3、 User Variables:用户参数，适用于参数取值范围很小的时候使用；4、 User Defined Variables:用户自定义变量，一般用于test plan中不需要随请求迭代的参数设置；]]></content>
      <categories>
        <category>Jmeter</category>
      </categories>
      <tags>
        <tag>Jmeter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jmeter连接mysql数据库]]></title>
    <url>%2F2020%2F01%2F17%2FJmeter%E8%BF%9E%E6%8E%A5mysql%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[1、下载数据库驱动，放至D:\apache-jmeter-5.1.1\lib\ext目录下 2、在顶层目录《测试计划》中加载驱动，点击【浏览】按钮，在jmeter/lib目录下选择mysql驱动包。如图所示： 3、新增线程组，右键添加-&gt;配置元件-&gt; JDBC Connection Configuration 4、配置数据库信息1）Variable Name数据库变量名，不能为空，后续JDBC Request中会用到这个值2）DataBase URL 格式为：jdbc:mysql://服务器ip:端口号/数据库名称3）JDBC Driver Class：com.mysql.jdbc.Driver4）输入连接的数据库用户名和密码 5、线程组右键添加-取样器-JDBC Request 6、添加变量和查询语句Variable Name：数据库变量名，必须和JDBC Connection Configuration中的Variable Name保持一致 按照下面的操作执行，执行单条sql语句时可以执行成功，执行多条的时候，报错了，这时需要配置数据库信息DataBase URL那里在数据库后加参数?allowMultiQueries=true,就可同时执行多条mysql语句；否则报错 7、执行查询语句 可以看到上方写的两条查询sql脚本已经能够查询出数据。]]></content>
      <categories>
        <category>Jmeter</category>
      </categories>
      <tags>
        <tag>Jmeter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jmeter常用快捷键]]></title>
    <url>%2F2020%2F01%2F16%2FJmeter%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[JMeter常用快捷键： Ctrl + C 复制 Ctrl + V 粘贴 Ctrl + Shift + C 复制粘贴当前组件到下一行Ctrl + R 运行测试计划 Ctrl + E 清空运行结果 Ctrl + T 启用/禁用当前组件 Ctrl + F 全文搜索 Ctrl + - 全部收起 Ctrl + Shift + - 全部展开 Ctrl + 0 创建线程组 Ctrl + 1 新增HTTP请求 Ctrl + 2 正则表达式提取器 Ctrl + 3 响应断言 Ctrl + 4 固定定时器 Ctrl + 5 Test Action Ctrl + 7 JSR223 PreProcessor Ctrl + 8 Debug Sampler Ctrl + 9 查看结果树]]></content>
      <categories>
        <category>Jmeter</category>
      </categories>
      <tags>
        <tag>Jmeter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jmeter介绍]]></title>
    <url>%2F2020%2F01%2F16%2FJmeter%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[一、Jmeter简介 Apache JMeter是100%纯JAVA桌面应用程序，被设计为用于测试客户端/服务端结构的软件(例如web应用程序)。它可以用来测试静态和动态资源的性能，例如：静态文件，Java Servlet,CGI Scripts,Java Object,数据库和FTP服务器等等。JMeter可用于模拟大量负载来测试一台服务器，网络或者对象的健壮性或者分析不同负载下的整体性能。 同时，JMeter可以帮助你对你的应用程序进行回归测试。通过你创建的测试脚本和assertions来验证你的程序返回了所期待的值。为了更高的适应性，JMeter允许你使用正则表达式来创建这些assertions. 二、安装Jmeter运行环境安装JDK下载地址：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html JDK环境变量配置 a、安装JDK 选择安装目录 安装过程中会出现两次 安装提示 。第一次是安装 jdk ，第二次是安装 jre 。建议两个都安装在同一个java文件夹中的不同文件夹中。（不能都安装在java文件夹的根目录下，jdk和jre安装在同一文件夹会出错）正确的安装如下图所示 b、安装完JDK后配置环境变量 计算机→右键属性→高级系统设置→高级→环境变量 c、系统变量→新建 JAVA_HOME 变量 变量值填写上面安装jdk的安装目录，这里注意根据自己安装的路径来写，不是都一样（本人是 C:\Program Files\Java\jdk1.8.0_101)所以填的这个路径。 d、系统变量→寻找 Path 变量→编辑 在变量值最后输入 %JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;（注意原来Path的变量值末尾有没有;号，如果没有的话，记得要先输入；号再输入上面的代码） e、系统变量→新建 CLASSPATH 变量 变量值填写.;%JAVA_HOME%\lib;%JAVA_HOME%\lib\tools.jar（注意最前面有一点）系统变量配置完毕 f、检验是否配置成功运行cmd 输入 java -version （java 和 -version 之间有空格） 若如图所示 显示版本信息 则说明安装和配置成功。 安装JMeter下载最新版本的JMeter，解压缩到本地任意目录，下载地址如下： http://jmeter.apache.org/download_jmeter.cgi 运行JMeter a) 进入bin目录运行jmeter.bat启动JMeter b) 注意：打开的时候会有两个窗口，JMeter的命令窗口和JMeter的图形操作界面，不可以关闭命令窗口。 c) Jmeter默认为英文界面，可通过修改安装路径下bin目录下的 jmeter.properties中#language=en所在的第37行修改为language=zh_CN（记得去掉注释#）重启后即为中文界面]]></content>
      <categories>
        <category>Jmeter</category>
      </categories>
      <tags>
        <tag>Jmeter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDLE如何清屏]]></title>
    <url>%2F2019%2F04%2F10%2FIDLE%E5%A6%82%E4%BD%95%E6%B8%85%E5%B1%8F%2F</url>
    <content type="text"><![CDATA[IDLE如何清屏1、下载ClearWindow.py（最下面有代码，保存为ClearWindow.py）。 2、拷贝ClearWindow.py文件，放在Python安装目录Python XXX\Lib\idlelib下面（XXX为你的python版本）。3、记事本打开Python XXX\Lib\idlelib目录下的config-extensions.def（IDLE扩展的配置文件）， 为防止出错，你可以在打开它之前先copy一个备份 。 4、修改config-extensions.def ，在末尾添加如下内容，然后保存退出：123456[ClearWindow]enable=1enable_editor=0enable_shell=1[ClearWindow_cfgBindings]clear-window=&lt;Control-Key-;&gt; 5、打开Python的IDLE，options选项中就可以看到增加了Clear shell window ctrl+;。 6、在IDLE输入代码，然后按Ctrl+;（是指Ctrl和;），发现刚输入代码可以被清除了。 ClearWindow.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980"""Clear Window ExtensionVersion: 0.2Author: Roger D. Serwy roger.serwy@gmail.comDate: 2009-06-14It provides "Clear Shell Window" under "Options"with ability to undo.Add these lines to config-extensions.def[ClearWindow]enable=1enable_editor=0enable_shell=1[ClearWindow_cfgBindings]clear-window=&lt;Control-Key-l&gt;"""class ClearWindow: menudefs = [ ('options', [None, ('Clear Shell Window', '&lt;&lt;clear-window&gt;&gt;'), ]),] def __init__(self, editwin): self.editwin = editwin self.text = self.editwin.text self.text.bind("&lt;&lt;clear-window&gt;&gt;", self.clear_window2) self.text.bind("&lt;&lt;undo&gt;&gt;", self.undo_event) # add="+" doesn't work def undo_event(self, event): text = self.text text.mark_set("iomark2", "iomark") text.mark_set("insert2", "insert") self.editwin.undo.undo_event(event) # fix iomark and insert text.mark_set("iomark", "iomark2") text.mark_set("insert", "insert2") text.mark_unset("iomark2") text.mark_unset("insert2") def clear_window2(self, event): # Alternative method # work around the ModifiedUndoDelegator text = self.text text.undo_block_start() text.mark_set("iomark2", "iomark") text.mark_set("iomark", 1.0) text.delete(1.0, "iomark2 linestart") text.mark_set("iomark", "iomark2") text.mark_unset("iomark2") text.undo_block_stop() if self.text.compare('insert', '&lt;', 'iomark'): self.text.mark_set('insert', 'end-1c') self.editwin.set_line_and_column() def clear_window(self, event): # remove undo delegator undo = self.editwin.undo self.editwin.per.removefilter(undo) # clear the window, but preserve current command self.text.delete(1.0, "iomark linestart") if self.text.compare('insert', '&lt;', 'iomark'): self.text.mark_set('insert', 'end-1c') self.editwin.set_line_and_column() # restore undo delegator self.editwin.per.insertfilter(undo)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[登录用例]]></title>
    <url>%2F2019%2F01%2F03%2F%E7%99%BB%E5%BD%95%E7%94%A8%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[现在，针对“用户登录”功能，基于等价类划分和边界值分析方法，我们设计的测试用例包括： 输入已注册的用户名和正确的密码，验证是否登录成功； 输入已注册的用户名和不正确的密码，验证是否登录失败，并且提示信息正确； 输入未注册的用户名和任意密码，验证是否登录失败，并且提示信息正确； 用户名和密码两者都为空，验证是否登录失败，并且提示信息正确； 用户名和密码两者之一为空，验证是否登录失败，并且提示信息正确； 如果登录功能启用了验证码功能，在用户名和密码正确的前提下，输入正确的验证码，验证是否登录成功； 如果登录功能启用了验证码功能，在用户名和密码正确的前提下，输入错误的验证码，验证是否登录失败，并且提示信息正确。列出这些测试用例后，你可能已经觉得比较满意了，因为你感觉已经把自己的测试知识都用在这些用例设计中了。 有经验的测试工程师会再增加的测试用例： 用户名和密码是否大小写敏感； 页面上的密码框是否加密显示； 后台系统创建的用户第一次登录成功时，是否提示修改密码； 忘记用户名和忘记密码的功能是否可用； 前端页面是否根据设计要求限制用户名和密码长度； 如果登录功能需要验证码，点击验证码图片是否可以更换验证码，更换后的验证码是否可用； 刷新页面是否会刷新验证码； 如果验证码具有时效性，需要分别验证时效内和时效外验证码的有效性； 用户登录成功但是会话超时后，继续操作是否会重定向到用户登录界面； 不同级别的用户，比如管理员用户和普通用户，登录系统后的权限是否正确； 页面默认焦点是否定位在用户名的输入框中； 快捷键 Tab 和 Enter 等，是否可以正常使用。 看完这些用例，你可能会说：“哇塞，原来一个简简单单的登录功能居然有这么多需要测试的点”。但是，你别高兴得太早，“用户登录”功能的测试还没结束。虽然改进后的测试用例集相比之前的测试覆盖率的确已经提高了很多，但是站在资深测试人员的角度来看，还有很多用例需要设计。经我这么一说，你可能已经发现，上面所有的测试用例设计都是围绕显式功能性需求的验证展开的，换句话说，这些用例都是直接针对“用户登录”功能的功能性进行验证和测试的。但是，一个质量过硬的软件系统，除了显式功能性需求以外，其他的非功能性需求即隐式功能性需求也是极其关键的。显式功能性需求（Functional requirement）的含义从字面上就可以很好地理解，指的是软件本身需要实现的具体功能， 比如“正常用户使用正确的用户名和密码可以成功登录”、“非注册用户无法登录”等，这都是属于典型的显式功能性需求描述。那什么是非功能性需求（Non-functional requirement）呢？从软件测试的维度来看，非功能性需求主要涉及安全性、性能以及兼容性三大方面。 在上面所有的测试用例设计中，我们完全没有考虑对非功能性需求的测试，但这些往往是决定软件质量的关键因素。如下： 安全性测试用例包括： 用户密码后台存储是否加密； 用户密码在网络传输过程中是否加密； 密码是否具有有效期，密码有效期到期后，是否提示需要修改密码； 不登录的情况下，在浏览器中直接输入登录后的 URL 地址，验证是否会重新定向到用户登录界面； 密码输入框是否不支持复制和粘贴；密码输入框内输入的密码是否都可以在页面源码模式下被查看； 用户名和密码的输入框中分别输入典型的“SQL 注入攻击”字符串，验证系统的返回页面； 用户名和密码的输入框中分别输入典型的“XSS 跨站脚本攻击”字符串，验证系统行为是否被篡改； 连续多次登录失败情况下，系统是否会阻止后续的尝试以应对暴力破解； 同一用户在同一终端的多种浏览器上登录，验证登录功能的互斥性是否符合设计预期； 同一用户先后在多台终端的浏览器上登录，验证登录是否具有互斥性。 性能压力测试用例包括: 单用户登录的响应时间是否小于 3 秒； 单用户登录时，后台请求数量是否过多； 高并发场景下用户登录的响应时间是否小于 5 秒； 高并发场景下服务端的监控指标是否符合预期； 高集合点并发场景下，是否存在资源死锁和不合理的资源等待； 长时间大量用户连续登录和登出，服务器端是否存在内存泄漏。 兼容性测试用例包括： 不同浏览器下，验证登录页面的显示以及功能正确性； 相同浏览器的不同版本下，验证登录页面的显示以及功能正确性； 不同移动设备终端的不同浏览器下，验证登录页面的显示以及功能正确性； 不同分辨率的界面下，验证登录页面的显示以及功能正确性 补充： 网络延迟或者弱网或者切换网络或者断网时正常登录是否正常 是否支持第三方登录 是否可记住密码，记住的密码保存是否加密 记住密码是否有有效期，有有效期，过期之后是否会清空密码 用户名密码是否支持特殊字符和中文等 是否可以使用登录的API发送登录请求，并绕开验证码校验 是否可以用抓包工具抓到的请求包直接登录 截取到的token等信息，是否可以在其他终端上直接使用，绕开登录。token过期时间校验 除了前端校验格式长度等，后端是否也校验？ 登录后输入登录URL，是否还能再次登录？如果能，原登录用户是否变得无效 登录错误后的提示是否有安全隐患 输入账号密码时对键盘格式是否有要求比如数字键盘； 密码一栏是否需要设置明暗码切换按钮； 输入账号密码格式不规范时是否将按钮设置为不可点击； 输入栏是否设置快速删除按钮 用户名和密码是否对空格敏感 更改密码后是否还能用之前的密码登录 一个用户是否具备多种登录方式(用户名，手机号，邮箱…) 若支持手机号+验证码登录，验证码是否有时间限制？移动端设备是否可以直接获取验证码登录？ 1、登录失败后二次登录（1）输入正确的用户名，不输入密码，点击登录；登录失败后，再次输入正确的密码登录并观察登录情况（2）输入正确的用户名和错误的密码登录失败后，再次输入正确的密码登录并观察登录情况（3）输入未注册的用户和任意密码登录失败后，再次输入正确的用户名和密码，观察登录情况2、修改密码后（1）修改完密码后是否重定向到登录界面（2）修改完密码后，分别使用原密码和新密码登录（3）在其他终端修改密码后，本终端是否自动下线？下线后，使用原密码能否继续登录？3、退出登录（1）退出登录是否有记住账号或记住密码功能（2）退出登录后，再次输入密码登录4、数据同步（1）第一次登录时，数据的同步情况，如个人头像，好友列表等（2）本终端切换其他账号登录后，数据的同步情况，日志记录情况，如：用户文件夹是否自动创建5、账号互踢（1）不同页面下被踢，如：后台运行时被踢，进入前台查看反应；前台运行时一级、二级页面下被踢能否提示正确并重定向到登录界面（2）本终端被踢下线后点击登录能否再次登录6、密码错误限制次数（1）密码输入错误是否有最大次数限制？分别测试最大值-1、最大值、最大值+1时的输错密码情况（2）超过最大次数限制后，是否采取强制手段限制登录或对账号暂时冻结处理（3）超过最大次数限制后，分别输入正确的密码和错误的密码再次登录7、安全性（1）本终端用户已登录，在其他终端尝试登录本用户账号登录失败时、本终端是否有账号异常操作的安全提示（2）输入密码时是否有安全键盘模式？点击密码输入框是否能调起安全键盘？（1）无网络模式下登录，是否给出“网络未连接”或“网络异常”的提示及提示是否正确（2）第一次登录请求超时后（服务器出问题，随后恢复正常），再次请求登录能否登录成功（3）第一次无网络情况下登录失败后，再次连接网络并登录（4）正在登录过程中，遇到网络切换，如（4G切换到WiFi环境时）能否正常登录8、其他（1）已登录的用户，杀死APP进程后，再次打开APP是否依然为已登录状态]]></content>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[换了电脑如何使用hexo继续写博客]]></title>
    <url>%2F2019%2F01%2F02%2F%E6%8D%A2%E4%BA%86%E7%94%B5%E8%84%91%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8hexo%E7%BB%A7%E7%BB%AD%E5%86%99%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[电脑中病毒了，换了系统，无法使用hexo再发布文章到个人博客，百度找教程0.0特此记录一下，万一哪天又中病毒了呢！ 一、安装必要软件 安装Git客户端 安装node.js 二、原文件拷贝将你原来电脑上个人博客目录下必要文件拷到你的新电脑上（比如D:/Blog目录下），注意无需拷全部，只拷如下几个目录：12345config.ymlpackage.jsonscaffolds/source/themes/ 三、安装 hexo在 cmd 下输入下面指令安装 hexo：1npm install hexo-cli -g 四、进入 D:/Blog 目录（你拷贝到新电脑的目录），输入下面指令安装相关模块12npm installnpm install hexo-deployer-git --save // 文章部署到 git 的模块 五、在github官网添加新电脑产生的秘钥 Github 添加 SSH Keys 首先在本地创建 SSH Keys:1$ ssh-keygen -t rsa -C "15754367707@163.com" 后面的邮箱即为 github 注册邮箱，也是登录 Github 的邮箱，之后会要求确认路径和输入密码，一路回车就行。 成功的话会在 ~/下生成 .ssh文件夹，进去，打开 id_rsa.pub，复制里面的key即可。 输入 eval “$(ssh-agent -s)” ，添加密钥到ssh-agent，再输入 ssh-add ~/.ssh/id_rsa ，添加生成的SSH key到ssh-agent 然后我们再次测试下公钥有没有添加成功：ssh -T git@github.com 六、测试 这时候使用 hexo s 基本可以看到你新添加的文章了。 七、部署发布文章123hexo clean // 清除缓存 网页正常情况下可以忽略此条命令hexo g // 生成静态网页hexo d // 开始部署]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[端口被占用问题]]></title>
    <url>%2F2018%2F11%2F15%2F%E7%AB%AF%E5%8F%A3%E8%A2%AB%E5%8D%A0%E7%94%A8%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[当我们同时安装了Oracle和Tomcat的时候，Tomcat启动时就会报错说端口被占用了。那么如何来解决呢?两种方法： 第一种方法就是修改我们的Tomcat的端口号，改成其他不冲突的即可。方便简单 第二种方法就是结束当前占用端口的进程，下面是具体步骤： 以我电脑进程为例： 1.打开cmd 输入 netstat -ano|findstr 8080 //说明：查看占用8080端口的进程 2.接着输入 taskkill /pid 2956 /f 2956是占用端口的进程 //说明：结束掉占用端口号的进程 但是呢这种方法只能是一时的，下次启动还是会占用的。个人认为修改端口较好。一次解决。]]></content>
      <categories>
        <category>问题+解决方法记录</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[winscp上传文件发生错误码4的问题]]></title>
    <url>%2F2018%2F06%2F20%2Fwinscp%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%8F%91%E7%94%9F%E9%94%99%E8%AF%AF%E7%A0%814%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关于使用winscp 上传文件发生错误码4的问题，各种百度找资料，最后的原因竟然是磁盘容量不足。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;换个物理分区，重新上传就好了。 所以下次遇到类似错误时，我觉得，对应磁盘的容量和权限也是一个排除的方向。]]></content>
      <categories>
        <category>问题+解决方法记录</category>
      </categories>
      <tags>
        <tag>WinScp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看Linux系统配置的命令]]></title>
    <url>%2F2018%2F06%2F09%2F%E6%9F%A5%E7%9C%8BLinux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E7%9A%84%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[一：CPU1[root@zhoumingyan /]# cat /proc/cpuinfo 二：内存1[root@zhoumingyan /]# cat /proc/meminfo 三：查看CPU位数1231.[root@zhoumingyan /]# getconf LONG_BIT2.[root@zhoumingyan /]# uname -i 四：查看Linux版本121.[root@zhoumingyan /]# cat /etc/issue2.[root@zhoumingyan /]# cat /proc/version 五：查看内核版本1[root@zhoumingyan /]# uname -a 六：主机名1[root@zhoumingyan /]# hostname 七：查看selinux情况1[root@zhoumingyan /]# sestatus 八：网络 IP 1[root@zhoumingyan /]# ifconfig 网关 1[root@zhoumingyan /]# cat /etc/sysconfig/network DNS 1[root@zhoumingyan /]# cat /etc/resolv.conf 修改HOST文件 1[root@zhoumingyan /]# cat /etc/hosts 九：磁盘和分区1[root@zhoumingyan /]# df -h 十：查看键盘布局1[root@zhoumingyan /]# cat /etc/sysconfig/keyboard 十一：查看默认语言1[root@zhoumingyan /]#cat /etc/sysconfig/i18n 十二：查看文件或目录在磁盘空间的大小1[root@zhoumingyan /]#du -h]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2F2018%2F06%2F09%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1.1 find功能：在linux文件系统中，用来查找一个文件放在哪里了。 举例：find /etc -name “interfaces” 总结： （1）什么时候用find？ 当你知道你要找的文件名，但是你忘记了它被放在哪个目录下，要找该文件时，用find. （2）怎么用find？123456find 路径 -name &quot;文件名&quot;find ./ -name 文件或文件夹名1.命令中的./ 指的是当前目录下，如果要整个系统下查找，可以用/即可；2.在其他目录下，就将./变为其他目录的绝对路径即可。 1.2 grep功能：在一个文本文件中，查找某个词 举例：grep -nr “SUN” * （1）什么时候用grep？ 当你想查找某个符号在哪些地方（有可能是一个文件，也可能是多个文件组成的文件夹）出现过，就用grep. （2）怎么用？ grep -nr “要查找的符号” 要查找的目录或文件集合 注意：-n表示查找结果中显示行号，-r表示要递归查找 1.3 which和whereis 功能：查找一个应用程序（二进制文件）在哪里 举例：which ls whereis ls(查找更详细) 区别：which 只显示二进制的路径 whereis显示二进制的路径，和其源码或man书册位置 1.4 uname 功能：查看系统信息 举例：123uname -a 查看系统所有信息 uname -n 网络结点名 uname -r 内核版本 1.5 开机和关机1234shutdown -h now 立即关机init 0 关机shutdown -r now 立即重启reboot 重启 1.6 tree/lstree 功能：显示文件和目录由根目录开始的树形结构 1.7 mount/umount 功能：用来挂载磁盘到文件系统中 举例：12mount -t nfs -o nolock 192.168.1.141:root/rootfs/mnt 挂载 umount /mnt 卸载 1.8 磁盘空间相关123df -h 显示已挂载的分区列表du -h 列出文件或文件夹的大小du -h 文件名 可以列出这个文件有多大，列出方式是以人比较好看懂的方式。不像ls -l 列出的都是以字节为单位。 1.9 用户管理123useradd user1 添加一个名为user1的用户userdel user1 删除一个名为user1的用户passwd user1 为名为user的用户设置密码 1.10 权限管理123chmod （change mode,修改文件权限）比较常用，要记得chown （change owner,修改属主）chgrp（change group,修改文件的组） ls -l 列出的属性 -rwxr-xr-x 一共10个字符，第一个表示文件属性（d表示文件夹，-表示普通文件），剩下的9个分成三组。每组中三个分别表示r可读w可写x可执行。如果是字母表示有这个权限，如果是-表示没有这个权限。三组分别表示：第一组表示文件属主的权限，第二组表示所属主所在的组用户的权限，第三组表示其他用户的权限。权限还有另一种表示方法，用数字来表示。 123456789编码规则如下：r 可读 4w 可写 2x 可执行 1- 无权限 0有了这个编码规则，则rwxr -xr-x 编码后为755第一种修改权限的方法：要把权限改成 rwxr--r--则对应的编码值为744修改命令为：chmod 744 文件名 第二种修改权限方法： 在原来的权限基础上进行修改，即增加或减少某权限。 三个组用户的编码依次为：属主u 属主所在的组g 其他用户o123456789譬如：要属主增加可执行权限 chmod u+x 文件名其他用户增加可执行权限 chmod o+w 文件名属主所在组用户去掉可执行权限 chmod g-x 文件名1.11 文件打包压缩与解压缩tar -czvf dir.tar.gz dir/ 将dir目录打包成dir.tar.gztar -cjvf dir.tar.bz2 dir/ 将dir目录打包成dir.tar.bz2tar -zxvf dir.tar.gz 解压缩dir.tar.gztar -jxvf dir.tar.bz2 解压缩dir.tar.bz2 1.12 sed和awk 正则表达式。匹配加替换 1.13 格式化文件系统12mkfs /dev/hd1mkfs -t vfat 32 -F /dev/hd1 创建一个FAT32文件系统 1.14 网络配置命令123456ifconfig eth0 192.168.1.13 设置IP地址ifconfig eth0 up 启动网卡ifconfig eth0 down 禁用网卡ifup eth0 启动网卡ifdown eth0 禁用网卡ifconfig eth0 192.168.1.1 netmask 255.255.255.0 同时设置IP和子网掩码 命令–help命令的简单帮助 man ==命令的复杂帮助 help ==命令的帮助（bash的内置命令） ls ==list，查看目录列表，-l(long)，-d(directory) mkdir ==make directory作用是创建目录，例如:mkdir /data -p 递归创建目录 cd ==change directory 作用切换路径，例如：cd / touch ==摸一下，作用是创建文件，例如：touch oldboy.txt vi ==编辑器，相当于记事本，有编辑功能，但较弱 vim ==复杂编辑器。相当于，emeditor editplus，notepad++ echo ==打印输出内容。配合“&gt;或&gt;&gt;”可以为文件覆盖及追加内容1echo&quot;oldboy oldgirl&quot;&gt;oldboy.txt cat ==查看文件内容 特殊用法：增加多行内容123456789101112cat &gt;&gt;/data/oldboy.txt&lt;&lt;EOFI am studing linux.EOFEOF要成对出现，EOF可以被任意成对内容替换cp ==copy 复制命令ctrl+c，例如：cp oldboy.txt /tmp/-r：递归，用于复制目录；-p保持属性-a: 相当于 -pdrcp==&apos;cp -i&apos; -i需要确认mv ==移动目录或文件，例如：mv /data/root/pwd ==print work directory 查看当前用户所在的路径rm ==remove 删除文件或目录 -f强制,-r删除目录 生产场景尽量不要使用rm，如果非要使用，一定要先cp等备份 替代方法： mv移动到一个临时目录。回收站。 find删除 1234567891011121314151617find /root/data -type f -exec rm -f &#123; &#125; \;find /root/data -type f |xargs rm -ffind ***** 查找-type 按文件类型查找，-name按照名字查找，查找的内容最好用双引号括起来，!取反。在 man find中搜索 输入/type 如果没搜到 按小写n继续搜 f代表文件 d代表目录&#123;&#125;：find找到的内容-exec到\：都是参数（它与额外命令之前后都要空格） 处理查找的结果rm -f 前面找到内容处理命令ls -l&#123;&#125;:额外命令 \；是bash是特殊的应用，；就是反斜杆转义touch 可以并排创建多个文件\让一个有意义的字符，脱掉马甲.. 上级目录.当前目录 想要它变成一个点 \.代表.号。| 管道（把前一个命令结果的输出交给后一个命令继续处理）find 另一个删除命令:find /root/data/ -type f |xargs rm -f 按名字查找要有双引号 所有的linux命令只要有参数可以接多个 删除一个目录下的所有文件，但保留一个指定的文件 退出到上一级目录 cd .. 或cd../ rm -r data 或rmdir data #里面是空目录了不需要-rf 总结：1234567891011..绝对路径，表示上一级目录。例如 /mnt/oldboy,mnt就是oldboy的上一级目录.相对路径，表示当前目录，即当前命令行的目录rm[-irf][文件/目录] ----删除文件/目录-i：询问用户是否确认删除，用y或者n来回答-r: 删除目录时加该选项，删除目录及目录下的文件和目录，可以递归删除-f: 强制删除，不用确认rmdir[-p][目录名]：用来删除空目录，-p 表示递归删除目录，目录里不能有文件或目录如：a/b/crmdir /a/b/c 会删除/a/b/c。而/a/b还在。rmdir -p /a/b/c 会删除/a,/a/b,/a/b/c 8.已知文件test.txt内容为： test liyao oldboy请给出打印text.txt内容时，不包含oldboy字符串的命令12345678cat&gt;test.txt&lt;&lt;EOF~]#grep -v &quot;oldboy&quot; text.txt test liyao~]# head -2 text.txt test liyao~]#cat text.txt |grep -v &quot;oldboy&quot; text.txt head ==头部，取文件的前N行，不加参数默认前10行， 取前三行-n 3 简写就是 -3tail ==尾巴，取文件的后N行，不加参数默认后10行， 取最后三行-n 3 简写就是 -3 -f 跟踪一个文件尾部的时时变化 awk** 一门语言，过滤内容(擅长取列) linux三剑客 老大awk -F “分割符号”‘ { print $1}’文件 &lt;==$1第一列,$2第二列 ..$NF 最后一列最后一列减一倒数第二列 $(NF-1)123456例：awk‘ &#123; print $1&#125;’awk.txt awk -F&quot;“:”‘ &#123; print $1&#125;’awk.txt 指定冒号为分隔符 awk -F&quot;“:”‘ &#123; print $1“”$2&quot;&quot; $3&#125;’awk.txt 例：awk &apos;&#123;if(NR&lt;31&amp;&amp;NR&gt;19) printf $1&quot;\n&quot;&#125;&apos; test.txt NR表示行号 &amp;&amp; (and )并且 \n回车换行 grep** ==擅长过滤器，把想要的或者不想要的分离开。-v排除 linux三剑客 老三123grep -E &quot;3306|1521&quot; /etc/services==egrep &quot;3306|1521&quot; /etc/services -E过滤多个字符串 -v排除 -i 不区分大小写 -o输出精确匹配的字符而不是默认的整行 想要什么接什么 一般用双引号 例：grep “oldboy” text.txt 不想要加-v 例：grep -v “oldboy” text.txt123456789#Context control-B 除了显示匹配的一行之外，并显示该行之前的num行-A 除了显示匹配的一行之外，并显示该行之后的num行-C 除了显示匹配的一行之外，并显示该行之前后各num行例：打印20-30行grep 30 -B 10 test.txt 匹配的内容30前面n行显示出来grep 20 -A 10 test.txt 匹配的内容20之后n行显示出来grep 25 -C 5 test.txt 匹配的内容前后5行显示出来grep &quot;匹配的字符串&quot; -B 参数 文件 sed(stream editor)**擅长取行，替换 linux三剑客 老二 sed*过滤：sed -n ‘/过滤的内容/处理的命令’ 文件 -n 取消sed的默认输出 -i 改变文件内容 set***替换 sed ‘s#oldboy#oldgirl#g’只改变输出 改变内容加-i sed -i‘s#oldboy#oldgirl#g’ find /root/data -type f -name “test.txt”|xargs sed -i‘s#oldboy#oldgirl#g’ 例子：sed ‘/oldboy/d’test.txt sed -n &apos;/oldboy/p&apos; test.txt 处理的命令：p print打印，d delete 删除 n 取消默认输出 9.请用一条命令完成创建目录/oldboy/test,即创建/oldbooy目录及test目录mkdir -p /oldboy/test123实践过程：~]#mkdir -p /oldboy/test 递归创建目录，一般第一级目录不存在时用-p，否则报错~]#tree /oldboy/ 查看目录树结果 yum linux里包管理器，yum帮助解决依赖问题 例子：yum install tree -y （-y直接装） 下载tree包，然后调用rpm命令安装tree包 如果需要依赖包，帮你下载帮提前安装 rpm -i install -v -h human（安装、显示输出，人类可读展示） rpm -ivh 包名.rpm（提前下载好） 最大问题，依赖问题不好解决：a——-b——-c——–d1234~]#yum install tree -y 安装tree包~]#rpm -qa tree 查看tree包版本 &lt;===q query -a alltree-1.5.3.2.e16.x86_64 tree 显示目录树结构 乱码解决 字符集问题 LANG==en 最小化安装缺包用yum install tree nmap sysstat lrzsz dosunix -y安装 软件包下载下来 rpm格式 rpm -ivh包名 yum update 更新所有软件到最新版本 10.已知/tmp目录下一句存在了test.txt文件，如何执行命令才能把/mnt/test.txt拷贝到/tmp下覆盖/tmp/test.txt，而让linux系统不提示是否覆盖（root权限下） 法一：用全路径 /bin/cp /mnt/test.txt /tmp/法二： \cp /mnt/test.txt /tmp/ alias 查看以及定义别名（外号、小名） 例子：oldboy=&apos;echo&quot;i am oldboy linux.&quot;&apos; alias rm=&apos;echo&quot;rm can not be used,pls use mv.&quot;&apos; 别名生效的位置：root用户：grep alias /root/.bashrc 所有用户都生效：/etc/bashrc或者/etc/profile定义 生效 source /etc/profile 别名的作用：1)通过给危险命令加一些保护参数，防止人为误操作2)把很多复杂的字符串或命令变成一个简单的字符串或命令。unalias 取消别名~用户的家目录，针对root环境~就代表/root seq==sequence 序列 -s指定序列的分隔符123456789101112131415161718~]# seq 2 52345~]# seq 1 2 10 奇数13579~]# seq 2 2 10 偶数246810横着输出 seq -s “@&quot; 5 @为分隔符 11.只查看ett.txt文件(100行)内第20行到第30行的内容 123456seq 100 &gt;test.txt seq 100追加到测试文件里法一：head -30 test.txt|tail -11 不推荐 效率慢循坏 for n in ‘seq 201 300&apos;; do echo $n&gt;&gt;test.text.txt;sleep 1;done法二：sed -n &apos;20，30p&apos; test.txt 常用 简单 易用 高效只取一行 sed -n &apos;30p&apos; test.txt 法三：awk &apos;&#123;if(NR&lt;31&amp;&amp;NR&gt;19) printf $1&quot;\n&quot;&#125;&apos; test.txt 12.分析图片服务日志，把日志（每个图片访问次数 *图片大小总和）排行， 取top10，也就是计算每个url的总访问大小 13.把/oldboy目录及其子目录下所有以扩展名.sh结尾的文件中包含./hostlists.txt的字符串 全部替换成../idctest_iplist.12find ./ -name &quot;*.sh&quot; -type f -exec sed -i &apos;s#./hostlists.txt#../idctest_iplist#g&apos;&#123;&#125; \;find /root/data -type f -name &quot;test.txt&quot;|xargs sed -i‘s#oldboy#oldgirl#g’ (1)sed替换12345sed -i &apos;s#oldboy#oldgirl#g&apos; a.txts 常说的查找并替换，用一个字符串替换成另一个g(global)与s联合使用时，表示对当前全局匹配替换（与下一个g意义不同）-i修改文件内容#是分隔符，可以用/@等替换 （2）find查找find / -type f -name “a.txt”history 打印用户操作的历史记录{} 输出字符序列或者字符序列 快捷键使用：12345678910Tab 命令或路径补全键，linux里最有用的ctrl+shift+c 复制ctrl+shift+v 粘贴命令结尾到命令开头 ctrl+a命令开头到命令结尾 ctrl+e剪切光标前的内容 ctrl+u剪切光标后的内容 ctrl+kctrl+c 终止当前任务命令或程序ctrl+l 清屏 clearctrl+d 退出当前会话 相当于exit,logout 基础正则表达式：一些特殊的符号 表示一些特殊的作用和功能12345678. 单个任意字符*重复前面任意0个或多个字符.*匹配任意字符sed -i ‘s#(可以用正则匹配)#\1#g’oldboy.txtawk -F &quot;:&quot;‘&#123;print $1 &quot; &quot; $2&quot; &quot; $NF&#125;’oldboy.txt linux优化： 建立普通账号，使用普通用户登录 处理SELINUX。 处理防火墙。 精简开机自启动服务。sshd,network,crond,rsyslog,sysstat LINUX最小化安全理念。5条 1.查询文件使用情况du -h *]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 目录结构]]></title>
    <url>%2F2018%2F06%2F04%2FLinux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[/：根目录 /usr:包含所有的命令、程序库、文档和其它文件等。这些文件在正常操作下不会被改变的。这个目录也包含你的linux发行版本的主要的应用程序，如Netscape. /var:包含在正常操作中被改变的文件：假脱机文件、记录文件、加锁文件、临时文件和页格式化文件等。这个目录中存放着那些不断在扩充着的东西，为了保持/usr的相对稳定，那些经常被修改的目录可以放在这个目录下，实际上许多系统管理员都是这样干的。顺带说一下系统的日志文件就在/var/log目录中。 /home：用户的主目录。这个目录在系统升级时应该保留。 /proc:是一个虚拟的目录，它是系统内存的映射。它们实际上并不存在磁盘上，也不占用空间。（用ls -l可以显示它们的大小）当查看这些文件时，实际上是访问存在内存中的信息，这些信息用于访问系统 /bin：系统启动时需要的执行文件(二进制),这些文件可以被普通用户使用。 /sbin：系统执行文件(二进制),这些文件不打算被普通用户使用。（普通用户仍然可以使用它们，但要指定目录） /etc:操作系统的配置文件目录 /root:系统管理员的Home目录 /dev：设备文件目录。Linux下设备被当成文件，这样一来硬件被抽象化，便于读写、网络共享以及需要临时装载到文件系统中。正常情况下，设备会有一个独立的目录。这些设备的内容会出现在独立的子目录下。Linux没有所谓的驱动符。 /lib：存放系统最基本的动态链接共享库 /boot:用于自举加载程序的文件。当计算机启动时，这些文件首先被加载。 /opt：可选的应用程序。 /tmp:临时文件。该目录会被自动清理干净。 /lost+found:在文件系统修复时恢复的文件。这个目录平时是空的，当系统不正常关机后，这里就成了无家可归的文件的避难所了。 /mnt:这个目录是空的，系统提供这个目录是让用户临时挂载别的文件系统。 小结： 本地管理员安装额外的软件安装在/usr/local目录下并符号链接在/usr/local/bin下的主执行程序。 系统的所有设置在/etc目录下。 不要修改根目录和/usr目录下的任何内容]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hwclock命令]]></title>
    <url>%2F2018%2F04%2F22%2Fhwclock%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[hwclock命令123hwclock 显示当前时间hwclock --hctosys 将系统时钟调整为与目前的硬件时钟一致。hwclock --set --date=&lt;日期与时间&gt; 设定硬件时钟。 1、date1234查看系统时间# date设置系统时间# date --set “07/07/06 10:19" （月/日/年 时:分:秒） 2、hwclock/clock12345678查看硬件时间# hwclock --show或者# clock --show设置硬件时间# hwclock --set --date="07/07/06 10:19" （月/日/年 时:分:秒）或者# clock --set --date="07/07/06 10:19" （月/日/年 时:分:秒） 3、硬件时间和系统时间的同步 按照前面的说法，重新启动系统，硬件时间会读取系统时间，实现同步，但是在不重新启动的时候，需要用hwclock或clock命令实现同步。 硬件时钟与系统时钟同步：12345# hwclock --hctosys（hc代表硬件时间，sys代表系统时间）或者# clock --hctosys系统时钟和硬件时钟同步：# hwclock --systohc 或者# clock --systohc]]></content>
      <categories>
        <category>常用linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[du命令]]></title>
    <url>%2F2018%2F04%2F20%2Fdu%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[dudu命令是检查硬盘使用情况，统计文件或目录及子目录使用硬盘的空间大小。参数的不同组合，可以更快的提高工作效率，以下仅列出了经常使用到的参数，如需更详细的信息，请用man du命令来获得。 1．命令格式1du [选项][文件] 2．命令功能显示每个文件和目录的磁盘使用空间。 3．命令参数说明1234567891011121314151617181920-a显示所有目录或文件的大小-b以byte为单位，显示目录或文件的大小-c显示目录或文件的总和-k以KB为单位输出-m以MB为单位输出-s仅显示目录或文件的总计数值-h以K,M,G为单位，提高信息可读性-x跳过不同的文件系统目录-S显示目录的大小，但不含子目录大小。-D显示指定符号链接的源文件大小 12345678910111213显示目录或者文件所占空间# du显示指定文件所占空间#du 文件名查看指定目录所占空间#du 目录名显示文件和目录#du -ah 目录名显示两个目录所占磁盘空间大小#du yum yum.bakevar目录中的某个文件太大，就可以使用如下命令查看# du -s /var/*|sort -nrSort -nr 从大到小排列倒叙排列，将占用磁盘空间最大的文件最先显示出来 举例： 1.查看当前目录下所有目录以及子目录的大小123#du -h ."."代表当前目录下。也可以换成一个明确的路径-h 表示用K/M/G的形式显示 2.查看当前目录abc目录的大小，不看其他目录12345678910#du -ch abc|tail -n 1-c 表示会列出文件空间大小的总和，用于计算几个文件的大小之和# du -sh abc-s表示总结的意思，即只列出一个目录中所有文件的空间大小的总值# du -h -max-depth=0 abc-max-depth＝n表示只深入到第n层目录，此处设置为0，即表示不深入到子目录。 列出abc目录及其子目录下所有目录和文件的大小 12# du -ah abc-a表示路径下的所有包括目录和文件 列出所有abc目录中的目录名不包括xyz字符串的目录的大小 1# du -h –exclude=’*xyz*’ 想在一个屏幕下列出更多的关于abc目录及子目录大小的信息 12# du -0h abc-0（杠零）表示每列出一个目录的信息，不换行，而是直接输出下一个目录的信息。]]></content>
      <categories>
        <category>常用linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[df命令]]></title>
    <url>%2F2018%2F04%2F17%2Fdf%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[dfdf命令作用是列出文件系统的整体磁盘空间使用情况。可以用来查看磁盘已被使用多少空间和还剩余多少空间。 df命令显示系统中包含每个文件名参数的磁盘使用情况，如果没有文件名参数，则显示所有当前已挂载文件系统的磁盘空间使用情况 在默认情况下，磁盘空间是以1KB为单位进行显示的，但是，如果POSIXLY_CORRECT环境变量被设置为true，这种情况下默认使用512字节为单位显示 df命令语法1df [选项] [文件名] 参数：12345678910111213141516-a：--all，显示所有的文件系统，包括虚拟文件系统-B：--block-size，指定单位大小。比如1k，1m等-h：--human-readable，以人们易读的GB、MB、KB等格式显示-H：--si，和-h参数一样，但是不是以1024，而是1000，即1k=1000，而不是1k=1024-i：--inodes，不用硬盘容量，而是以inode的数量来显示-k：以KB的容量显示各文件系统，相当于--block-size=1k-m：以KB的容量显示各文件系统，相当于--block-size=1m-l：--local，只显示本地文件系统--no-sync：在统计使用信息之前不调用sync命令(默认)-sync：在统计使用信息之前调用sync命令-P：--portability，使用POSIX格式显示-t：--type=TYPE，只显示指定类型的文件系统-T：--print-type，显示文件系统类型-x：--exclude-type=TYPE，不显示指定类型的文件系统--help：显示帮助信息--version：显示版本信息 df命令示例 示例1:查看包含给定文件磁盘空间使用情况12345678910111213141516171819[root@localhost ~]# df /home #指定一个文件夹，查看该文件夹所在磁盘的使用情况Filesystem 1K-blocks Used Available Use% Mounted on/dev/sda2 16036224 2749160 12459316 19% / [root@localhost ~]# df /bin/ls #指定一个文件Filesystem 1K-blocks Used Available Use% Mounted on/dev/sda2 16036224 2749160 12459316 19% / [root@localhost ~]# df /bin/ls /home #指定多个文件或文件夹Filesystem 1K-blocks Used Available Use% Mounted on/dev/sda2 16036224 2749160 12459316 19% //dev/sda2 16036224 2749160 12459316 19% / [root@localhost ~]# df # 默认情况Filesystem 1K-blocks Used Available Use% Mounted on/dev/sda2 16036224 2750464 12458012 19% //dev/sda1 295561 16911 263390 7% /boottmpfs 1028272 0 1028272 0% /dev/shm 输出结果列说明： Filesystem：代表该文件系统时哪个分区，所以列出的是设备名称。 1K-blocks：说明下面的数字单位是1KB，可利用-h或-m来改变单位大小，也可以用-B来设置。 Used：已经使用的空间大小。 Available：剩余的空间大小。 Use%：磁盘使用率。如果使用率在90%以上时，就需要注意了，避免磁盘容量不足出现系统问题，尤其是对于文件内容增加较快的情况(如/home、/var/spool/mail等)。 Mounted on：磁盘挂载的目录，即该磁盘挂载到了哪个目录下面。]]></content>
      <categories>
        <category>常用linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[less命令]]></title>
    <url>%2F2018%2F04%2F16%2Fless%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[lessless 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。 在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup] [pagedown] 等按 键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。 1．命令格式：1less [参数] 文件 2．命令功能：less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。 3．命令参数：1234567891011121314151617181920212223242526-b &lt;缓冲区大小&gt; 设置缓冲区的大小-e 当文件显示结束后，自动离开-f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件-g 只标志最后搜索的关键词-i 忽略搜索时的大小写-m 显示类似more命令的百分比-N 显示每行的行号-o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来-Q 不使用警告音-s 显示连续空行为一行-S 行过长时间将超出部分舍弃-x &lt;数字&gt; 将“tab”键显示为规定的数字空格/字符串：向下搜索“字符串”的功能?字符串：向上搜索“字符串”的功能n：重复前一个搜索（与 / 或 ? 有关）N：反向重复前一个搜索（与 / 或 ? 有关）b 向后翻一页d 向后翻半页h 显示帮助界面Q 退出less 命令u 向前滚动半页y 向前滚动一行空格键 滚动一行回车键 滚动一页[pagedown]： 向下翻动一页[pageup]： 向上翻动一页 4．使用实例：实例1：ps查看进程信息并通过less分页显示同时显示行号1#ps -ef|less -N 实例2.浏览多个文件1#less test2.log test.log 说明：输入 ：n后，切换到 test.log输入 ：p 后，切换到test2.logps：当正在浏览一个文件时，也可以使用 :e命令 打开另一个文件。命令：less file1:e file2 5．附加备注5.1.全屏导航1234ctrl + F - 向前移动一屏ctrl + B - 向后移动一屏ctrl + D - 向前移动半屏ctrl + U - 向后移动半屏 5.2.单行导航12j - 向前移动一行k - 向后移动一行 5.3.其它导航123G - 移动到最后一行g - 移动到第一行q / ZZ - 退出 less 命令 5.4.其它有用的命令123v - 使用配置的编辑器编辑当前文件h - 显示 less 的帮助文档&amp;pattern - 仅显示匹配模式的行，而不是整个文件 6.标记导航123当使用 less 查看大文件时，可以在任何一个位置作标记，可以通过命令导航到标有特定标记的文本位置：ma - 使用 a 标记文本的当前位置'a - 导航到标记 a 处 7.查找1more, less 都具备查找功能，按/ 然后输入要找的字串，再按 Enter 即可，按 n(next) 会继续找，大写的 N 则是往回(上)找，按 q(quit)或者ZZ离开]]></content>
      <categories>
        <category>常用linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[more命令]]></title>
    <url>%2F2018%2F04%2F15%2Fmore%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[moremore功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。 1．命令格式：1more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ] 2．命令功能：more命令和cat的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。 3．命令参数：123456789+n 从笫n行开始显示-n 定义屏幕大小为n行+/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示-d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能-l 忽略Ctrl+l（换页）字符-p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似-s 把连续的多个空行显示为一行-u 把文件内容中的下画线去掉 4．常用操作命令：123456789Enter 向下n行，需要定义。默认为1行Ctrl+F 向下滚动一屏空格键 向下滚动一屏Ctrl+B 返回上一屏= 输出当前行的行号：f 输出文件名和当前行的行号V 调用vi编辑器!命令 调用Shell，并执行命令 q 退出more 5．命令实例：实例1：显示文件中从第3行起的内容命令：12# cat test.log #显示所有日志内容# more +3 test.log #从第三行开始显示日志内容 实例2.将日志内容设置为每屏显示4行命令：1# more -4 test.log 实例3.从文件中查找第一个出现”liu”字符串的行，并从该处前两行开始显示输出命令：1#more +/liu test.log 实例4.当一个目录下的文件内容太多，可以用more来分页显示。这得和管道 | 结合起来命令：1#cat test.log | more -5 #“|”表示管道，作用是可以将前面命令的输出当做后面命令的输入]]></content>
      <categories>
        <category>常用linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tail命令]]></title>
    <url>%2F2018%2F04%2F14%2Ftail%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[taillinux tail命令用途是依照要求将指定的文件的最后部分输出到标准设备，通常是终端，通俗讲来，就是把某个档案文件的最后几行显示到终端上，假设该档案有更新，tail会自己主动刷新，确保你看到最新的档案内容。 tail命令语法1tail [ -f ] [ -c Number | -n Number | -m Number | -b Number | -k Number ] [ File ] 参数解释：1234567-f 该参数用于监视File文件增长。-c Number 从 Number 字节位置读取指定文件-n Number 从 Number 行位置读取指定文件。-m Number 从 Number 多字节字符位置读取指定文件，比方你的文件假设包括中文字，假设指定-c参数，可能导致截断，但使用-m则会避免该问题。-b Number 从 Number 表示的512字节块位置读取指定文件。-k Number 从 Number 表示的1KB块位置读取指定文件。File 指定操作的目标文件名称 上述命令中，都涉及到number，假设不指定，默认显示10行。Number前面可使用正负号，表示该偏移从顶部还是从尾部開始计算。 tail可运行文件一般在/usr/bin/以下。 tail命令使用方法演示例子 1、tail -f filename 说明：监视filename文件的尾部内容（默认10行，相当于增加参数 -n 10），刷新显示在屏幕上。退出，按下CTRL+C。 2、tail -n 20 filename 说明：显示filename最后20行。 3、tail -r -n 10 filename说明：逆序显示filename最后10行。 补充： 跟tail功能相似的命令还有： cat 从第一行開始显示档案内容。 tac 从最后一行開始显示档案内容。 more 分页显示档案内容。 less 与 more 相似，但支持向前翻页 head 仅仅显示前面几行 tail 仅仅显示后面几行 n 带行号显示档案内容 od 以二进制方式显示档案内容]]></content>
      <categories>
        <category>常用linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[head命令]]></title>
    <url>%2F2018%2F04%2F13%2Fhead%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[headhead 与 tail 就像它的名字一样的浅显易懂，它是用来显示开头或结尾某个数量的文字区块，head 用来显示档案的开头至标准输出中，而 tail 就是看档案的结尾。 1．命令格式：1head [参数]... [文件]... 2．命令功能：head 用来显示档案的开头至标准输出中，默认head命令打印其相应文件的开头10行。 3．命令参数：1234-q 隐藏文件名-v 显示文件名-c&lt;字节&gt; 显示字节数-n&lt;行数&gt; 显示的行数 4．使用实例：实例1：显示文件的前n行命令：1head -n 5 log.log 实例2：显示文件前n个字节命令：1head -c 20 log.log 实例3：文件的除了最后n个字节以外的内容命令：1head -c -32 log.log 实例4：输出文件除了最后n行的全部内容命令：1head -n -6 log.log]]></content>
      <categories>
        <category>常用linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ls命令]]></title>
    <url>%2F2018%2F04%2F12%2Fls%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[ls (list,列表)作用：使用列表把当前文件夹下所有文件夹显示出来 命令格式：1ls [选项] [目录名] 常用举例：1ls -a 列出文件下所有的文件，包括以“.“开头的隐藏文件 1ls -l 列出文件的详细信息，将文件的权限、所有者、文件大小等信息详细列出来 1ls -F 在每一个文件的末尾加上一个字符说明该文件的类型。"@"表示符号链接、"|"表示FIFOS、"/"表示目录、"="表示套接字。 1ls -s 在每个文件的后面打印出文件的大小。 size(大小) 1ls -t 按时间进行文件的排序 Time(时间) 1ls -A 列出除了"."和".."以外的文件。 1ls -R 将目录下所有的子目录的文件都列出来，相当于我们编程中的“递归”实现 1ls -L 列出文件的链接名。Link（链接） 1ls -S 以文件的大小进行排序 命令：ls -l t* 可以查看当前目录下文件名以“t”开头的所有文件的信息。其实，在命令格式中，方括号内的内容都是可以省略的，对于命令ls而言，如果省略命令参数和操作对象，直接输入“ ls ”，则将会列出当前工作目录的内容清单。 命令：ls -ltr s* 列出目前工作目录下所有名称是s 开头的档案，越新的排越后面。 命令：ls -AF 列出目前工作目录下所有档案及目录;目录于名称后加”/“, 可执行档案于名称后加”*” 输出：123[root@localhost opt]# ls -AFlog/ script/ soft/ src/ svndata/ web/ 计算当前目录下的文件数和目录数 命令：123ls -l * |grep "^-"|wc -l ---查看文件个数 ls -l * |grep "^d"|wc -l ---查看目录个数 彩色目录列表颜色的含义如下: 1234567891. 蓝色--&gt;目录2. 绿色--&gt;可执行文件3. 红色--&gt;压缩文件4. 浅蓝色--&gt;链接文件5. 灰色--&gt;其他文件]]></content>
      <categories>
        <category>常用linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pwd命令]]></title>
    <url>%2F2018%2F04%2F11%2Fpwd%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[pwd（print work directory 打印工作目录）作用：打印出当前的绝对路径 命令格式：1pwd [选项] 不太确定当前位置时，就会使用pwd来判定当前目录在文件系统内的确切位置 常用举例：1234[root@localhost /]# cd /opt/data/[root@localhost data]# pwd/opt/data[root@localhost data]# 目录连接链接时，pwd -P 显示出实际路径，而非使用连接（link）路径；pwd显示的是连接路径 命令：1pwd -P 输出： 1234567891011[root@localhost soft]# cd /etc/init.d [root@localhost init.d]# pwd/etc/init.d[root@localhost init.d]# pwd -P/etc/rc.d/init.d[root@localhost init.d]#]]></content>
      <categories>
        <category>常用linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cd命令]]></title>
    <url>%2F2018%2F04%2F10%2Fcd%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[cd (change directory,更改目录)作用：用来切换目录 【涉及到相对路径和绝对路径 命令格式：1cd [目录名] 跳转到指定目录，从根目录开始，目录名称前加 / ,当前目录内的子目录直接写名称即可. 常用举例：1cd /opt/soft 进入到/opt/soft 1cd / 进入系统根目录 1cd ~ 进入当前用户主目录 1cd . . 代表当前目录 1cd .. .. 代表上一层目录 1cd - 返回上次所在目录 1cd ../.. 返回上两级目录]]></content>
      <categories>
        <category>常用linux命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql常用语句]]></title>
    <url>%2F2018%2F02%2F02%2FMysql%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[创建数据库 create database 数据库名 例：create database test; 创建表 create table 表名称 DEFAULT CHARSET=utf8; 操作数据库 向表插入数据1insert [into] 表名 values (值1, 值2, 值3, ...); 向表中字段插入数据1insert [into] 表名 [(列名1, 列名2, 列名3, ...)] values (值1, 值2, 值3, ...); 向表中字段插入多条数据 1insert [into] 表名 [(列名1, 列名2, 列名3, ...)] values (值1, 值2, 值3, ...), (值1, 值2, 值3, ...), (值1, 值2, 值3, ...); 删 1delete from 表名称 where 删除条件; 改 1update 表名称 set 列名称=新值 where 更新条件; 查1select 列名称 from 表名称 [查询条件]; 多表查询1select 要查询的字段 from 表1,表2 where 关联条件 模糊查询1select from 表名称 where 字段名 like &apos;%值a%&apos; 统计查询 1select count(*) from 表名称 where 条件表达式 分组查（GROUP BY） 对表的修改 重命名表1alter table 表名 rename 新表名; 删除整张表1drop table 表名; 删除整个数据库1drop database 数据库名; 其他 asc(升序) desc(降序)]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[测试基础]]></title>
    <url>%2F2018%2F01%2F02%2F%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[一、软件测试目标 基于软件测试的目标，站在不同的立场，有两种完全不同的观点。从用户的角度出发，用户普遍希望通过软件测试暴露软件中隐藏的错误和缺陷，以考虑是否可以接受该产品；那么从软件开发者的角度来说，他们希望测试成为表明软件中不存在错误的过程，验证该软件已正确的实现了用户的要求，确立人们对软件质量的信心。 由于一个软件产品不可能完全正确，没有bug,如果只是为了表明软件产品中不存在错误，那么这样的软件测试对于软件质量的提高和功能的完善没有任何的帮助。所以，归根到底，软件测试就是为了发现软件产品中错误和缺陷，然后软件开发人员对错误和缺陷进行修复，提高软件的质量，最后提交一个满足用户需求的软件产品。 《软件测试艺术》中有这样的观点： 软件测试是程序的执行过程，目的在于发现错误 测试是为了证明程序有错，而不是证明程序无错误 一个好的测试用例在于能发现至今未发现的错误 一个成功的测试是发现了至今未发现的错误的测试]]></content>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
</search>
